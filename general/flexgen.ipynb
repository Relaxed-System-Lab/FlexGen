{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Policy, logging\n",
    "# from forward import flexgen\n",
    "from test import test_hf_gen\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "checkpoint = \"facebook/opt-125m\" # 125m 6.7b 13b 30b\n",
    "# checkpoint = \"Salesforce/codegen-350M-mono\"\n",
    "# checkpoint = 'bigscience/bloom-560m'\n",
    "\n",
    "policy = Policy(\n",
    "    gpu_batch_size=2, \n",
    "    num_gpu_batches=4, \n",
    "    weights_gpu_percent=0.0, \n",
    "    weights_cpu_percent=0.3, \n",
    "    cache_gpu_percent=0.0, \n",
    "    cache_cpu_percent=0.2, \n",
    "    act_gpu_percent=0.0, \n",
    "    act_cpu_percent=0.5, \n",
    "    overlap=True, \n",
    "    pin_weight=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward.py: rewrite layer forward function\n",
    "\n",
    "import torch\n",
    "import functools \n",
    "import contextlib\n",
    "\n",
    "# from minibatch import get_size_info, load_kth_batch_inputs, concat_outputs\n",
    "from utils import get_module_from_name\n",
    "\n",
    "\n",
    "def reset_forward(model, layer_name):        \n",
    "    layer = get_module_from_name(model, layer_name) \n",
    "\n",
    "    if hasattr(layer, \"_flexgen_old_forward\"):\n",
    "        layer.forward = layer._flexgen_old_forward\n",
    "        delattr(layer, \"_flexgen_old_forward\")\n",
    "        logger.debug(f'{layer_name} from flexgen to old.')\n",
    "\n",
    "    if hasattr(layer, \"_test_old_forward\"):\n",
    "        layer.forward = layer._test_old_forward\n",
    "        delattr(layer, \"_test_old_forward\")\n",
    "        logger.debug(f'{layer_name} from test to old.')\n",
    "\n",
    "def to_test_forward(mpl, layer_name, call_layer_log):\n",
    "    layer = get_module_from_name(mpl.model, layer_name) \n",
    "    compute_device = 'cpu' \n",
    "    layer._test_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        mpl.load_layer_weights(layer_name, compute_device) \n",
    "\n",
    "        call_layer_log.append(layer_name)  # \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = old_forward(*args, **kwargs)\n",
    "\n",
    "        mpl.offload_layer_weights(layer_name)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    logger.debug(f'{layer_name} to test forward') \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def test(mpl, call_layer_log):\n",
    "    model = mpl.model\n",
    "    layer_names = mpl.layer_names\n",
    "\n",
    "    # test run to get layer calling order\n",
    "    for layer_name in layer_names:\n",
    "        to_test_forward(mpl, layer_name, call_layer_log)\n",
    "    yield \n",
    "    for layer_name in layer_names:\n",
    "        reset_forward(model, layer_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "from typing import Mapping, Tuple\n",
    "import numpy as np \n",
    "import os \n",
    "import torch\n",
    "from math import floor\n",
    "\n",
    "class MixTensor:\n",
    "    def __init__(\n",
    "        self, \n",
    "        mix_data: Tuple, \n",
    "        split_dim: int, \n",
    "        device: torch.device, \n",
    "        shape: torch.Size,\n",
    "        percents: Mapping[str, float],\n",
    "        file_path: str,\n",
    "        dtype\n",
    "    ):\n",
    "        self.mix_data = mix_data\n",
    "        self.split_dim = split_dim \n",
    "        self.device = device \n",
    "        self.shape = shape \n",
    "        self.percents = percents\n",
    "        self.file_path = file_path\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    def size(self):\n",
    "        return self.shape \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_split_dim(tensor):\n",
    "        dim_sizes = tensor.size()\n",
    "        max_dim, max_size = -1, -1\n",
    "        for dim, size in enumerate(dim_sizes):\n",
    "            if size > max_size:\n",
    "                max_size = size\n",
    "                max_dim = dim \n",
    "        return max_dim \n",
    "    \n",
    "    @staticmethod\n",
    "    def tensor_dim_slice(tensor, dim, dim_slice):\n",
    "        return tensor[(dim if dim >= 0 else dim + tensor.dim()) * (slice(None), ) + (dim_slice, )]\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_tensor(tensor, dim, percents):\n",
    "        dim_size = tensor.size(dim)\n",
    "        g_per, c_per, _ = [percents[dev] for dev in ['cuda', 'cpu', 'disk']]\n",
    "        \n",
    "        g_cut = floor(dim_size * g_per)\n",
    "        c_cut = floor(dim_size * (g_per + c_per))\n",
    "\n",
    "        g_data = MixTensor.tensor_dim_slice(tensor, dim, slice(0, g_cut))\n",
    "        c_data = MixTensor.tensor_dim_slice(tensor, dim, slice(g_cut, c_cut))\n",
    "        d_data = MixTensor.tensor_dim_slice(tensor, dim, slice(c_cut, dim_size))\n",
    "        return g_data, c_data, d_data \n",
    "\n",
    "    @classmethod\n",
    "    def from_tensor(\n",
    "        cls, \n",
    "        tensor: torch.Tensor, \n",
    "        percents: Mapping[str, float],\n",
    "        file_path: str \n",
    "    ):\n",
    "        split_dim = cls.get_split_dim(tensor) \n",
    "        device = tensor.device \n",
    "        shape = tensor.shape\n",
    "        dtype = tensor.dtype\n",
    "        \n",
    "        g_data, c_data, d_data = cls.split_tensor(tensor, split_dim, percents) \n",
    "        \n",
    "        g_data = g_data.to('cuda' if torch.cuda.is_available() else 'cpu') if g_data.numel() else None\n",
    "        c_data = c_data.to('cpu') if c_data.numel() else None\n",
    "        if d_data.numel():\n",
    "            d_data = d_data.cpu().numpy()\n",
    "            shape = d_data.shape\n",
    "            np_dtype = d_data.dtype \n",
    "\n",
    "            fp = np.memmap(file_path, mode=\"w+\", shape=shape, dtype=np_dtype)\n",
    "            fp[:] = d_data[:]\n",
    "            d_data = (shape, np_dtype)\n",
    "        else:\n",
    "            d_data = None \n",
    "        mix_data = (g_data, c_data, d_data)\n",
    "\n",
    "        return cls(\n",
    "            mix_data=mix_data,\n",
    "            split_dim=split_dim,\n",
    "            device=device,\n",
    "            shape=shape,\n",
    "            percents=percents,\n",
    "            file_path=file_path,\n",
    "            dtype=dtype\n",
    "        )\n",
    "\n",
    "    @classmethod \n",
    "    def from_mixtensor(cls, mix_tensor):\n",
    "        self = mix_tensor \n",
    "        return self \n",
    "\n",
    "    def to_tensor(self):\n",
    "        g_data, c_data, d_data = self.mix_data \n",
    "        compute_device = self.device \n",
    "\n",
    "        tensor = []\n",
    "        if g_data is not None:\n",
    "            if g_data.device != torch.device(compute_device):\n",
    "                g_data = g_data.to(compute_device) \n",
    "            tensor.append(g_data)\n",
    "        if c_data is not None:\n",
    "            if c_data.device != torch.device(compute_device):\n",
    "                c_data = c_data.to(compute_device) \n",
    "            tensor.append(c_data)\n",
    "        if d_data is not None:\n",
    "            (shape, np_dtype) = d_data \n",
    "            d_data = np.memmap(self.file_path, shape=shape, dtype=np_dtype, mode='r')\n",
    "            d_data = torch.from_numpy(d_data).to(compute_device)\n",
    "            tensor.append(d_data)\n",
    "            \n",
    "        tensor = torch.cat(tensor, dim=self.split_dim) \n",
    "\n",
    "        return tensor        \n",
    "\n",
    "    def __add__(self, mix_tensor):\n",
    "        assert self.shape == mix_tensor.shape and type(self) == type(mix_tensor) # is same shape mix tensor\n",
    "        res = self.to_tensor() + mix_tensor.to_tensor() \n",
    "        return self.from_tensor(res, self.percents, self.file_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    x = torch.tensor([1,2,3])\n",
    "    m = MixTensor.from_tensor(x, percents={'cuda':0, 'cpu':0.5, 'disk':0.5}, file_path='test/m.dat')\n",
    "    m2 = MixTensor.from_tensor(x, percents={'cuda':0, 'cpu':0.5, 'disk':0.5}, file_path='test/m2.dat')\n",
    "    m = m + m2\n",
    "    print(m.to_tensor())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "from accelerate.utils import honor_type\n",
    "from typing import Mapping\n",
    "from utils import logging \n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def get_type_size_info(obj): # recursive\n",
    "    if isinstance(obj, (tuple, list)):\n",
    "        return honor_type(obj, (get_type_size_info(o) for o in obj))\n",
    "    elif isinstance(obj, Mapping):\n",
    "        return type(obj)({k:get_type_size_info(v) for k, v in obj.items()})\n",
    "    \n",
    "    elif isinstance(obj, (torch.Tensor, MixTensor, BatchMixTensor)):\n",
    "        return f'{type(obj)}: {obj.size()}'\n",
    "\n",
    "    elif isinstance(obj, (int, bool, type(None))): \n",
    "        return f'{type(obj)}: {obj}'\n",
    "    else:\n",
    "        logger.warning(f'inputs: {obj} of type \\'{type(obj)}\\' is not implemented.')\n",
    "        return f'{type(obj)}: {obj}'\n",
    "\n",
    "def to_mixed_device(obj, policy, prefix): \n",
    "    if isinstance(obj, tuple) and len(obj) == 2 and isinstance(obj[0], torch.Tensor) and isinstance(obj[1], torch.Tensor): # KV cache\n",
    "        m0 = MixTensor.from_tensor(\n",
    "            obj[0], \n",
    "            percents={\n",
    "                'cuda':policy.cache_gpu_percent, \n",
    "                'cpu':policy.cache_cpu_percent, \n",
    "                'disk':policy.cache_disk_percent, \n",
    "            }, \n",
    "            file_path=f'{prefix}_key.dat'\n",
    "        )\n",
    "        m1 = MixTensor.from_tensor(\n",
    "            obj[1], \n",
    "            percents={\n",
    "                'cuda':policy.cache_gpu_percent, \n",
    "                'cpu':policy.cache_cpu_percent, \n",
    "                'disk':policy.cache_disk_percent, \n",
    "            }, \n",
    "            file_path=f'{prefix}_value.dat'\n",
    "        )\n",
    "        return (m0, m1)\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        return MixTensor.from_tensor(\n",
    "            obj, percents={\n",
    "                'cuda':policy.act_gpu_percent, \n",
    "                'cpu':policy.act_cpu_percent, \n",
    "                'disk':policy.act_disk_percent, \n",
    "            }, \n",
    "            file_path=f'{prefix}.dat'\n",
    "        )\n",
    "    elif isinstance(obj, tuple):\n",
    "        return honor_type(obj, (to_mixed_device(o, policy, f'{prefix}[{i}]') for i, o in enumerate(obj)))\n",
    "    else:\n",
    "        logger.warning(f'inputs: {obj} of type \\'{type(obj)}\\' is not implemented.')\n",
    "        return obj\n",
    "\n",
    "from typing import Iterable\n",
    "class BatchMixTensor:\n",
    "    def __init__(self, batches: Iterable[MixTensor]):\n",
    "        self.dtype = batches[0].dtype\n",
    "        self.device = batches[0].device\n",
    "        self.batches = batches \n",
    "\n",
    "        self.shape = self.size()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.batches[i]\n",
    "    \n",
    "    def __setitem__(self, i, mt: MixTensor):\n",
    "        self.batches[i] = mt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "    \n",
    "    def size(self):\n",
    "        shape = list(self[0].size()) \n",
    "        shape[0] *= len(self)\n",
    "        return torch.Size(shape)\n",
    "\n",
    "    def __add__(self, bmt):\n",
    "        for k in range(len(self)): # K batches \n",
    "            # TODO flexgen: parallelly load k+1\n",
    "            self_k = self[k].to_tensor()\n",
    "            bmt_k = bmt[k].to_tensor()\n",
    "            res = self_k + bmt_k \n",
    "            self[k] = MixTensor.from_tensor(res, self[k].percents, self[k].file_path)\n",
    "        return self \n",
    "\n",
    "    def contiguous(self):\n",
    "        tensor = []\n",
    "        for mt in self:\n",
    "            tensor.append(mt.to_tensor())\n",
    "        return torch.cat(tensor)\n",
    "\n",
    "def concat_outputs(outputs): # concatenate K outputs to one output\n",
    "    assert len(outputs), 'empty outputs.'\n",
    "    assert isinstance(outputs[0], (MixTensor, torch.Tensor, tuple)), f'not supported type: {type(outputs[0])}.'\n",
    "    \n",
    "    if isinstance(outputs[0], torch.Tensor):\n",
    "        return torch.cat(outputs, dim=0)\n",
    "    elif isinstance(outputs[0], MixTensor):\n",
    "        return BatchMixTensor(outputs)\n",
    "    elif isinstance(outputs[0], tuple):\n",
    "        def f(outputs):\n",
    "            ans = []\n",
    "            for elem in zip(*outputs):\n",
    "                if isinstance(elem[0], torch.Tensor):\n",
    "                    ans.append(torch.cat(elem, dim=0))\n",
    "                elif isinstance(elem[0], MixTensor):\n",
    "                    ans.append(BatchMixTensor(elem))\n",
    "                elif isinstance(elem[0], tuple):\n",
    "                    ans.append(f(elem))\n",
    "                else:\n",
    "                    logger.warning(f'outputs: {elem[0]} of type \\'{type(elem[0])}\\' is not implemented.')\n",
    "                    ans.append(elem[0])\n",
    "            return tuple(ans)\n",
    "\n",
    "        return f(outputs)\n",
    "\n",
    "\n",
    "def load_kth_batch_inputs(inputs, k, ngb): # for both args, kwargs, with a nested structure of tuple/list/dict/Tensor\n",
    "    if isinstance(inputs, (tuple, list)): # e.g. args\n",
    "        return honor_type(inputs, (load_kth_batch_inputs(inp, k, ngb) for inp in inputs))\n",
    "    elif isinstance(inputs, Mapping): # e.g. kwargs\n",
    "        return type(inputs)({key:load_kth_batch_inputs(value, k, ngb) for key, value in inputs.items()})\n",
    "    elif isinstance(inputs, torch.Tensor):\n",
    "        mini_size = inputs.size(0) // ngb\n",
    "        return inputs[k * mini_size:(k + 1) * mini_size]\n",
    "    elif isinstance(inputs, MixTensor):\n",
    "        inputs = inputs.to_tensor()\n",
    "        mini_size = inputs.size(0) // ngb\n",
    "        return inputs[k * mini_size:(k + 1) * mini_size]\n",
    "    elif isinstance(inputs, BatchMixTensor):\n",
    "        mini_batch = inputs.batches[k]\n",
    "        return mini_batch.to_tensor()\n",
    "    elif isinstance(inputs, (int, bool, type(None))): \n",
    "        return inputs\n",
    "    else:\n",
    "        logger.warning(f'inputs: {inputs} of type \\'{type(inputs)}\\' is not implemented.')\n",
    "        return inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def to_flexgen_forward(mpl, j, compute_device):\n",
    "    # rewrite the j-th layer's forward\n",
    "    layer_name = mpl.layer_names[j]\n",
    "    next_layer_name = mpl.layer_names[(j + 1) % len(mpl.layer_names)]\n",
    "\n",
    "    policy = mpl.policy\n",
    "    ngb = policy.num_gpu_batches\n",
    "\n",
    "    layer = get_module_from_name(mpl.model, layer_name)  \n",
    "    if hasattr(layer, \"_flexgen_old_forward\"): return  \n",
    "    \n",
    "    layer._flexgen_old_forward = old_forward = layer.forward \n",
    "\n",
    "    @functools.wraps(old_forward)\n",
    "    def new_forward(*args, **kwargs):\n",
    "        # pre fwd: load curr & next weights, TODO: cuda stream\n",
    "        mpl.load_layer_weights(layer_name, compute_device) \n",
    "        mpl.load_layer_weights(next_layer_name, compute_device) \n",
    "        \n",
    "        # loop forward pass of K minibatches, TODO: cuda stream\n",
    "        with torch.no_grad():\n",
    "            logger.debug(f'args: {get_type_size_info(args)}')\n",
    "            logger.debug(f'kwargs: {get_type_size_info(kwargs)}')\n",
    "            \n",
    "            outputs = []\n",
    "            for k in range(ngb):\n",
    "                logger.debug(f'layer: {layer_name}, batch: {k}')\n",
    "\n",
    "                # 'pre' fwd: load curr & next inputs (activations, KV cache)\n",
    "                args_k = load_kth_batch_inputs(args, k, ngb)\n",
    "                kwargs_k = load_kth_batch_inputs(kwargs, k, ngb)\n",
    "\n",
    "                # TODO: load args, kwargs to compute device\n",
    "\n",
    "                # the k-th fwd pass\n",
    "                output = old_forward(*args_k, **kwargs_k)\n",
    "\n",
    "                # TODO: 1) output: to mix, 2) args_k, kwargs_k: free\n",
    "                output = to_mixed_device(output, policy, prefix=f'tmp/{layer_name}_output')\n",
    "                outputs.append(output) \n",
    "\n",
    "            output = concat_outputs(outputs)\n",
    "            logger.debug(f'outputs after concat: {get_type_size_info(output)}')                \n",
    "\n",
    "        # post fwd: free curr weights\n",
    "        mpl.offload_layer_weights(layer_name)\n",
    "        return output\n",
    "\n",
    "    layer.forward = new_forward\n",
    "    logger.debug(f'{layer_name} to flexgen forward')\n",
    "\n",
    "@contextlib.contextmanager \n",
    "def flexgen(checkpoint, policy):\n",
    "    # init model \n",
    "    from model import ModelPolicyLoader\n",
    "    mpl = ModelPolicyLoader(checkpoint, policy)\n",
    "    mpl.init_all_weights() # init \n",
    "\n",
    "    # test run, get layer order\n",
    "    call_layer_log = []\n",
    "    with test(mpl, call_layer_log):\n",
    "        from test import test_hf_gen\n",
    "        test_hf_gen(mpl.checkpoint, mpl.model, 1,1, prompts=['0'])\n",
    "\n",
    "    assert len(call_layer_log) == len(mpl.layer_names) and set(call_layer_log) == set(mpl.layer_names)\n",
    "    mpl.layer_names = call_layer_log\n",
    "\n",
    "    # rewrite layer forward\n",
    "    for j, _ in enumerate(mpl.layer_names):\n",
    "        compute_device = 'cpu'\n",
    "        to_flexgen_forward(mpl, j, compute_device)\n",
    "    yield mpl.model \n",
    "    for layer_name in mpl.layer_names:\n",
    "        reset_forward(mpl.model, layer_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 12:35:59,231 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-11 12:35:59,381 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2023-10-11 12:35:59,467 [model.py:159 in is_on_disk] INFO - [], ['lm_head.weight']\n",
      "2023-10-11 12:35:59,506 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 12:35:59,596 [model.py:159 in is_on_disk] INFO - [], ['lm_head.weight']\n",
      "2023-10-11 12:35:59,598 [model.py:182 in download] INFO - The whole model has been downloaded an processed to offload_folder: 'offload_dir/facebook.opt-125m'\n",
      "2023-10-11 12:35:59,606 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_tokens, [0. 0. 1.], size_todo: 86630400\n",
      "2023-10-11 12:35:59,607 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.embed_positions, [0. 0. 1.], size_todo: 85056000\n",
      "2023-10-11 12:35:59,608 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.final_layer_norm, [0.00000000e+00 1.91116887e-05 9.99980888e-01], size_todo: 85054464\n",
      "2023-10-11 12:35:59,610 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.0, [0.         0.05002193 0.94997807], size_todo: 77966592\n",
      "2023-10-11 12:35:59,611 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.1, [0.         0.08698539 0.91301461], size_todo: 70878720\n",
      "2023-10-11 12:35:59,613 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.2, [0.         0.11542163 0.88457837], size_todo: 63790848\n",
      "2023-10-11 12:35:59,615 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.3, [0.         0.13797624 0.86202376], size_todo: 56702976\n",
      "2023-10-11 12:35:59,617 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.4, [0.       0.156303 0.843697], size_todo: 49615104\n",
      "2023-10-11 12:35:59,618 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.5, [0.       0.200013 0.799987], size_todo: 42527232\n",
      "2023-10-11 12:35:59,620 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.6, [0.         0.21055017 0.78944983], size_todo: 35439360\n",
      "2023-10-11 12:35:59,622 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.7, [0.         0.24389645 0.75610355], size_todo: 28351488\n",
      "2023-10-11 12:35:59,625 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.8, [0.         0.25000554 0.74999446], size_todo: 21263616\n",
      "2023-10-11 12:35:59,627 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.9, [0.         0.27657765 0.72342235], size_todo: 14175744\n",
      "2023-10-11 12:35:59,629 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.10, [0.         0.27999324 0.72000676], size_todo: 7087872\n",
      "2023-10-11 12:35:59,631 [model.py:138 in get_policy_weight_map] DEBUG - model.decoder.layers.11, [0.         0.30186053 0.69813947], size_todo: 0\n",
      "2023-10-11 12:35:59,632 [model.py:138 in get_policy_weight_map] DEBUG - lm_head, [0.         0.30186053 0.69813947], size_todo: 0\n",
      "2023-10-11 12:35:59,633 [model.py:142 in get_policy_weight_map] INFO - device_map is prepared!\n",
      "2023-10-11 12:35:59,636 [model.py:148 in get_policy_weight_map] INFO - CausalLM facebook/opt-125m is to be loaded on: \n",
      "GPU Mem 0.00 GiB (0.00%), CPU Mem 0.07 GiB (30.19%), Disk Mem 0.16 Gib (69.81%)\n",
      "2023-10-11 12:35:59,638 [model.py:241 in init_all_weights] DEBUG - init all weights...\n",
      "model init: loading by policy...: 100%|██████████| 197/197 [00:00<00:00, 8347.42it/s]\n",
      "2023-10-11 12:35:59,665 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.embed_tokens to test forward\n",
      "2023-10-11 12:35:59,666 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.embed_positions to test forward\n",
      "2023-10-11 12:35:59,666 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.final_layer_norm to test forward\n",
      "2023-10-11 12:35:59,668 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.0 to test forward\n",
      "2023-10-11 12:35:59,669 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.1 to test forward\n",
      "2023-10-11 12:35:59,669 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.2 to test forward\n",
      "2023-10-11 12:35:59,670 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.3 to test forward\n",
      "2023-10-11 12:35:59,671 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.4 to test forward\n",
      "2023-10-11 12:35:59,672 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.5 to test forward\n",
      "2023-10-11 12:35:59,672 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.6 to test forward\n",
      "2023-10-11 12:35:59,675 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.7 to test forward\n",
      "2023-10-11 12:35:59,675 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.8 to test forward\n",
      "2023-10-11 12:35:59,677 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.9 to test forward\n",
      "2023-10-11 12:35:59,678 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.10 to test forward\n",
      "2023-10-11 12:35:59,678 [520681597.py:42 in to_test_forward] DEBUG - model.decoder.layers.11 to test forward\n",
      "2023-10-11 12:35:59,679 [520681597.py:42 in to_test_forward] DEBUG - lm_head to test forward\n",
      "2023-10-11 12:35:59,719 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "/home/fsuser/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1535: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on meta. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('meta') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "2023-10-11 12:35:59,883 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:35:59,885 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,887 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:35:59,889 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,890 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:35:59,900 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,904 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:35:59,912 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,916 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:35:59,925 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,928 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:35:59,936 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,938 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:35:59,946 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,948 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:35:59,955 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,957 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:35:59,964 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,967 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:35:59,974 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,976 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:35:59,983 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,985 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:35:59,992 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:35:59,994 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:00,002 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,005 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:00,013 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:00,018 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,019 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:00,031 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,038 [test.py:40 in test_hf_gen] INFO - 0.\n",
      "2023-10-11 12:36:00,039 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:00,049 [520681597.py:22 in reset_forward] DEBUG - model.decoder.embed_tokens from test to old.\n",
      "2023-10-11 12:36:00,050 [520681597.py:22 in reset_forward] DEBUG - model.decoder.embed_positions from test to old.\n",
      "2023-10-11 12:36:00,051 [520681597.py:22 in reset_forward] DEBUG - model.decoder.final_layer_norm from test to old.\n",
      "2023-10-11 12:36:00,052 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.0 from test to old.\n",
      "2023-10-11 12:36:00,053 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.1 from test to old.\n",
      "2023-10-11 12:36:00,054 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.2 from test to old.\n",
      "2023-10-11 12:36:00,056 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.3 from test to old.\n",
      "2023-10-11 12:36:00,056 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.4 from test to old.\n",
      "2023-10-11 12:36:00,057 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.5 from test to old.\n",
      "2023-10-11 12:36:00,058 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.6 from test to old.\n",
      "2023-10-11 12:36:00,058 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.7 from test to old.\n",
      "2023-10-11 12:36:00,059 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.8 from test to old.\n",
      "2023-10-11 12:36:00,060 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.9 from test to old.\n",
      "2023-10-11 12:36:00,061 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.10 from test to old.\n",
      "2023-10-11 12:36:00,063 [520681597.py:22 in reset_forward] DEBUG - model.decoder.layers.11 from test to old.\n",
      "2023-10-11 12:36:00,064 [520681597.py:22 in reset_forward] DEBUG - lm_head from test to old.\n",
      "2023-10-11 12:36:00,065 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.embed_tokens to flexgen forward\n",
      "2023-10-11 12:36:00,065 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.embed_positions to flexgen forward\n",
      "2023-10-11 12:36:00,066 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.0 to flexgen forward\n",
      "2023-10-11 12:36:00,067 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.1 to flexgen forward\n",
      "2023-10-11 12:36:00,068 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.2 to flexgen forward\n",
      "2023-10-11 12:36:00,068 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.3 to flexgen forward\n",
      "2023-10-11 12:36:00,070 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.4 to flexgen forward\n",
      "2023-10-11 12:36:00,071 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.5 to flexgen forward\n",
      "2023-10-11 12:36:00,072 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.6 to flexgen forward\n",
      "2023-10-11 12:36:00,073 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.7 to flexgen forward\n",
      "2023-10-11 12:36:00,074 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.8 to flexgen forward\n",
      "2023-10-11 12:36:00,075 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.9 to flexgen forward\n",
      "2023-10-11 12:36:00,076 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.10 to flexgen forward\n",
      "2023-10-11 12:36:00,076 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.layers.11 to flexgen forward\n",
      "2023-10-11 12:36:00,077 [3420557143.py:50 in to_flexgen_forward] DEBUG - model.decoder.final_layer_norm to flexgen forward\n",
      "2023-10-11 12:36:00,078 [3420557143.py:50 in to_flexgen_forward] DEBUG - lm_head to flexgen forward\n",
      "2023-10-11 12:36:00,118 [connectionpool.py:456 in _make_request] DEBUG - https://huggingface.co:443 \"HEAD /facebook/opt-125m/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2023-10-11 12:36:00,258 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:00,260 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:00,261 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9])\",)\n",
      "2023-10-11 12:36:00,262 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:00,262 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:00,264 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:00,266 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:00,267 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:00,270 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\n",
      "2023-10-11 12:36:00,270 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,272 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:00,273 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:00,278 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 9])\", \"<class 'int'>: 0\")\n",
      "2023-10-11 12:36:00,279 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:00,280 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:00,282 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:00,283 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:00,285 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:00,287 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\n",
      "2023-10-11 12:36:00,288 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,292 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:00,297 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:00,302 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,302 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,303 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:00,314 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:00,325 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:00,331 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:00,338 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,339 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,342 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:00,347 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:00,352 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,352 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,353 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:00,361 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:00,368 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:00,375 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:00,383 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,384 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,388 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:00,392 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:00,397 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,397 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,398 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:00,406 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:00,414 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:00,419 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:00,428 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,429 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,432 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:00,439 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:00,446 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,448 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,448 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:00,471 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:00,478 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:00,491 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:00,498 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,499 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,502 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:00,507 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:00,512 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,513 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,514 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:00,521 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:00,527 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:00,533 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:00,543 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,544 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,547 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:00,551 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:00,555 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,556 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,557 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:00,569 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:00,574 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:00,581 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:00,588 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,590 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,592 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:00,596 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:00,601 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,601 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,602 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:00,609 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:00,614 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:00,621 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:00,626 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,627 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,629 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:00,634 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:00,639 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,639 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,640 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:00,646 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:00,652 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:00,658 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:00,663 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,664 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,666 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:00,670 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:00,675 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,676 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,677 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:00,683 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:00,690 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:00,695 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:00,702 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,702 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,705 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:00,709 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:00,714 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,715 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,716 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:00,744 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:00,756 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:00,762 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:00,770 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,771 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,774 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:00,780 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:00,785 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,786 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,787 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:00,797 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:00,807 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:00,813 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:00,819 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,819 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,822 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:00,826 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:00,828 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,828 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 9, 9])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': \"<class 'NoneType'>: None\", 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:00,830 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:00,837 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:00,845 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:00,852 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:00,859 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"))\n",
      "2023-10-11 12:36:00,860 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,862 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:00,863 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:00,865 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,865 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:00,866 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:00,868 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:00,870 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:00,872 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:00,874 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\n",
      "2023-10-11 12:36:00,876 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,877 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:00,878 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:00,880 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 9, 384])\",)\n",
      "2023-10-11 12:36:00,881 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:00,881 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:00,901 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:00,917 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:00,932 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:00,948 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 9, 25136])\n",
      "2023-10-11 12:36:00,950 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,976 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:00,977 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:00,980 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:00,980 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:00,981 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:00,983 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:00,984 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:00,986 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:00,987 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:00,988 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:00,990 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:00,991 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:00,996 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 10])\", \"<class 'int'>: 9\")\n",
      "2023-10-11 12:36:00,996 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:00,997 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:00,999 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:01,001 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:01,002 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:01,004 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:01,004 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,024 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:01,029 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:01,035 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,036 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,037 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:01,088 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:01,123 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:01,138 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:01,144 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,144 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,147 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:01,152 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:01,156 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,157 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,158 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:01,164 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:01,177 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:01,184 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:01,191 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,192 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,195 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:01,199 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:01,204 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,205 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,206 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:01,213 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:01,220 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:01,227 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:01,234 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,235 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,238 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:01,243 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:01,248 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,249 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,250 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:01,258 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:01,264 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:01,278 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:01,292 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,293 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,295 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:01,300 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:01,305 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,306 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,306 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:01,334 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:01,339 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:01,344 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:01,348 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,349 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,352 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:01,356 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:01,361 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,362 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,363 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:01,369 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:01,374 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:01,379 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:01,384 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,385 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,388 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:01,392 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:01,398 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,398 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,399 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:01,407 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:01,414 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:01,422 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:01,451 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,452 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,454 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:01,459 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:01,464 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,464 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,466 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:01,471 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:01,478 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:01,483 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:01,490 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,490 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,493 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:01,497 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:01,502 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,503 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,505 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:01,531 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:01,538 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:01,544 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:01,549 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,550 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,552 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:01,557 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:01,562 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,563 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,564 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:01,571 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:01,576 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:01,582 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:01,586 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,587 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,590 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:01,595 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:01,600 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,601 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,602 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:01,610 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:01,615 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:01,623 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:01,628 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,629 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,632 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:01,636 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:01,638 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,639 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 10])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 9, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,640 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:01,646 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:01,651 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:01,656 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:01,662 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"))\n",
      "2023-10-11 12:36:01,663 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,665 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:01,667 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:01,668 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,669 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:01,670 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:01,674 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:01,675 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:01,681 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:01,684 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:01,685 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,686 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:01,687 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:01,689 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,690 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:01,691 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:01,710 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:01,720 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:01,730 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:01,741 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:01,742 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,749 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:01,750 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:01,752 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:01,753 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:01,753 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:01,755 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:01,757 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:01,758 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:01,760 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:01,761 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,763 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:01,764 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:01,770 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 11])\", \"<class 'int'>: 10\")\n",
      "2023-10-11 12:36:01,771 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:01,771 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:01,773 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:01,775 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:01,777 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:01,778 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:01,779 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,783 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:01,788 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:01,793 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,794 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,795 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:01,801 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:01,808 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:01,813 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:01,818 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:01,819 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,821 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:01,826 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:01,831 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,832 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,833 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:01,841 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:01,846 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:01,851 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:01,856 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:01,857 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,859 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:01,864 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:01,869 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,870 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,871 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:01,878 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:01,884 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:01,890 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:01,908 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:01,909 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,911 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:01,916 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:01,921 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,923 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,923 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:01,930 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:01,949 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:01,955 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:01,967 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:01,968 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:01,970 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:01,975 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:01,980 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:01,981 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:01,982 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:01,989 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:01,994 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:01,999 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:02,004 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,005 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,008 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:02,012 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:02,017 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,018 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,019 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:02,027 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:02,031 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:02,036 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:02,042 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,043 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,045 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:02,050 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:02,056 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,057 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,058 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:02,082 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:02,087 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:02,092 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:02,097 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,098 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,100 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:02,105 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:02,113 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,115 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,116 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:02,126 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:02,135 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:02,141 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:02,147 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,148 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,150 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:02,155 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:02,160 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,161 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,162 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:02,169 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:02,175 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:02,181 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:02,198 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,198 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,201 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:02,205 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:02,210 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,211 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,212 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:02,221 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:02,226 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:02,232 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:02,236 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,237 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,240 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:02,244 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:02,249 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,250 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,251 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:02,258 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:02,269 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:02,278 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:02,293 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,294 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,297 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:02,302 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:02,303 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,304 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 11])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 10, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,305 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:02,311 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:02,316 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:02,327 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:02,345 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"))\n",
      "2023-10-11 12:36:02,346 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,349 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:02,350 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:02,352 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,353 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:02,353 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:02,357 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:02,359 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:02,361 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:02,362 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:02,363 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,365 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:02,366 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:02,368 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,368 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:02,370 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:02,381 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:02,391 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:02,400 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:02,410 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:02,411 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,418 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:02,420 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:02,421 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:02,421 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:02,422 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:02,425 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:02,426 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:02,427 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:02,429 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:02,430 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,431 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:02,433 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:02,437 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 12])\", \"<class 'int'>: 11\")\n",
      "2023-10-11 12:36:02,438 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:02,439 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:02,441 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:02,442 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:02,444 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:02,445 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:02,446 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,451 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:02,455 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:02,461 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,461 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,462 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:02,469 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:02,474 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:02,479 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:02,486 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,486 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,489 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:02,493 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:02,498 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,499 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,500 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:02,565 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:02,576 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:02,589 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:02,615 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,616 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,619 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:02,624 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:02,629 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,631 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,631 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:02,643 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:02,648 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:02,654 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:02,664 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,665 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,667 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:02,672 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:02,677 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,678 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,679 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:02,685 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:02,691 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:02,698 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:02,703 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,704 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,706 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:02,711 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:02,717 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,717 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,718 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:02,724 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:02,729 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:02,734 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:02,740 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,740 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,743 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:02,747 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:02,752 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,753 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,754 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:02,760 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:02,771 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:02,787 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:02,793 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,794 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,797 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:02,801 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:02,806 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,807 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,808 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:02,820 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:02,826 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:02,834 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:02,840 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,841 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,844 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:02,849 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:02,853 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,854 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,855 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:02,882 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:02,888 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:02,898 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:02,903 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,904 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,906 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:02,911 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:02,916 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,916 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,917 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:02,923 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:02,929 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:02,934 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:02,939 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,940 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,942 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:02,947 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:02,951 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,952 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,953 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:02,960 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:02,965 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:02,971 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:02,976 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:02,977 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:02,979 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:02,984 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:02,989 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:02,990 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:02,990 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:03,004 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:03,022 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:03,027 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:03,033 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:03,034 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,036 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:03,042 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:03,044 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,045 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 12])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 11, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,046 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:03,055 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:03,063 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:03,069 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:03,074 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"))\n",
      "2023-10-11 12:36:03,075 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,077 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:03,079 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:03,080 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,081 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,082 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:03,085 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:03,087 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:03,089 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:03,091 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:03,092 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,093 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:03,094 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:03,095 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,097 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,097 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:03,110 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:03,122 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:03,134 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:03,149 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:03,150 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,157 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:03,158 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:03,160 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:03,160 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,161 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:03,163 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:03,164 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:03,166 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:03,167 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:03,168 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,170 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:03,171 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:03,176 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 13])\", \"<class 'int'>: 12\")\n",
      "2023-10-11 12:36:03,177 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,178 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:03,180 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:03,182 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:03,183 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:03,185 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:03,186 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,190 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:03,195 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:03,199 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,200 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,201 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:03,207 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:03,213 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:03,217 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:03,222 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,223 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,225 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:03,230 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:03,235 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,235 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,236 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:03,243 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:03,279 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:03,301 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:03,315 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,316 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,318 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:03,323 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:03,328 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,329 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,330 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:03,336 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:03,343 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:03,348 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:03,354 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,355 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,358 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:03,363 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:03,368 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,369 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,370 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:03,376 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:03,381 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:03,387 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:03,392 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,393 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,395 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:03,400 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:03,405 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,406 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,407 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:03,413 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:03,418 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:03,423 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:03,429 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,430 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,432 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:03,436 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:03,441 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,442 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,443 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:03,451 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:03,462 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:03,467 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:03,477 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,478 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,480 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:03,485 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:03,490 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,490 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,491 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:03,510 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:03,516 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:03,521 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:03,527 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,528 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,530 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:03,535 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:03,539 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,540 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,541 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:03,554 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:03,560 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:03,574 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:03,579 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,580 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,583 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:03,588 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:03,593 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,594 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,595 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:03,606 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:03,614 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:03,621 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:03,626 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,627 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,629 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:03,634 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:03,639 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,640 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,641 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:03,647 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:03,652 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:03,658 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:03,663 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,663 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,666 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:03,670 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:03,675 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,676 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,677 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:03,687 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:03,700 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:03,706 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:03,711 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,712 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,714 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:03,719 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:03,720 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,721 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 13])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 12, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,722 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:03,739 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:03,744 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:03,750 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:03,755 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"))\n",
      "2023-10-11 12:36:03,756 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,758 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:03,760 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:03,761 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,762 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,762 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:03,766 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:03,770 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:03,772 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:03,774 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:03,775 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,776 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:03,778 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:03,779 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,780 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,781 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:03,798 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:03,806 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:03,816 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:03,825 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:03,827 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,834 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:03,835 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:03,837 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:03,839 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,839 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:03,841 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:03,842 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:03,844 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:03,845 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:03,846 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,848 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:03,850 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:03,855 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 14])\", \"<class 'int'>: 13\")\n",
      "2023-10-11 12:36:03,855 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:03,857 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:03,858 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:03,860 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:03,862 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:03,863 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:03,864 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,868 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:03,873 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:03,878 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,879 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,880 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:03,894 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:03,900 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:03,906 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:03,912 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:03,913 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,915 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:03,919 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:03,924 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,925 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,926 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:03,933 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:03,939 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:03,949 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:03,954 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:03,955 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,958 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:03,962 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:03,967 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:03,967 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:03,969 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:03,976 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:03,981 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:03,989 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:03,994 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:03,995 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:03,999 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:04,004 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:04,009 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,010 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,011 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:04,022 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:04,030 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:04,035 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:04,041 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,042 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,044 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:04,049 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:04,054 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,055 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,055 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:04,062 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:04,067 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:04,072 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:04,077 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,078 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:04,085 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:04,089 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,090 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,091 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:04,098 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:04,103 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:04,112 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:04,125 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,127 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,130 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:04,137 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:04,144 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,145 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,146 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:04,154 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:04,161 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:04,167 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:04,174 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,175 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,178 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:04,185 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:04,191 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,192 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,193 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:04,202 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:04,211 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:04,218 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:04,240 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,241 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,245 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:04,252 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:04,259 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,260 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,260 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:04,269 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:04,278 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:04,285 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:04,301 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,302 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,304 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:04,309 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:04,314 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,314 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,315 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:04,373 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:04,394 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:04,400 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:04,405 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,406 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,408 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:04,413 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:04,418 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,419 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,420 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:04,433 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:04,438 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:04,444 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:04,449 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,450 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,453 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:04,457 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:04,459 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,460 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 14])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 13, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,461 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:04,473 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:04,490 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:04,496 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:04,502 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"))\n",
      "2023-10-11 12:36:04,502 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,505 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:04,506 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:04,508 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,508 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:04,509 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:04,511 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:04,513 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:04,517 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:04,518 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:04,520 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,522 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:04,523 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:04,524 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,525 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:04,526 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:04,539 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:04,548 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:04,557 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:04,568 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:04,570 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,577 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:04,579 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:04,580 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:04,581 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:04,582 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:04,584 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:04,585 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:04,587 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:04,588 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:04,589 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,591 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:04,592 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:04,597 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 15])\", \"<class 'int'>: 14\")\n",
      "2023-10-11 12:36:04,597 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:04,598 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:04,600 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:04,602 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:04,604 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:04,605 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:04,606 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,610 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:04,614 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:04,619 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,620 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,621 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:04,627 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:04,633 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:04,639 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:04,644 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,645 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,647 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:04,652 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:04,657 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,658 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,659 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:04,666 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:04,671 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:04,675 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:04,681 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,681 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,684 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:04,689 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:04,694 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,695 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,696 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:04,702 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:04,716 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:04,722 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:04,728 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,728 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,731 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:04,736 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:04,741 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,742 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,743 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:04,750 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:04,755 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:04,760 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:04,765 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,766 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,768 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:04,773 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:04,778 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,779 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,780 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:04,786 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:04,793 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:04,799 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:04,804 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,805 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,808 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:04,812 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:04,817 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,818 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,819 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:04,825 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:04,835 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:04,840 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:04,845 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,846 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,849 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:04,854 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:04,859 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,860 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,861 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:04,902 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:04,908 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:04,914 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:04,925 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,926 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,929 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:04,934 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:04,938 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,939 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,940 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:04,948 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:04,953 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:04,959 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:04,969 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:04,970 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:04,974 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:04,979 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:04,984 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:04,992 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:04,994 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:05,049 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:05,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:05,081 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:05,096 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:05,097 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,099 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:05,104 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:05,108 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,109 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,110 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:05,176 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:05,206 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:05,214 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:05,221 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:05,222 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,224 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:05,228 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:05,233 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,234 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,235 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:05,245 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:05,252 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:05,261 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:05,268 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:05,269 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,273 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:05,280 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:05,282 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,283 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 15])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 14, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,284 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:05,292 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:05,299 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:05,307 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:05,315 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"))\n",
      "2023-10-11 12:36:05,316 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,319 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:05,321 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:05,323 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,323 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:05,324 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:05,328 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:05,331 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:05,335 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:05,338 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:05,339 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,341 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:05,343 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:05,345 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,347 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:05,348 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:05,362 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:05,380 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:05,391 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:05,402 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:05,404 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,411 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:05,413 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:05,414 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:05,415 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:05,415 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:05,417 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:05,419 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:05,421 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:05,422 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:05,423 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,425 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:05,426 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:05,431 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 16])\", \"<class 'int'>: 15\")\n",
      "2023-10-11 12:36:05,432 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:05,433 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:05,435 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:05,436 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:05,438 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:05,440 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:05,441 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,445 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:05,450 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:05,455 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,456 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,457 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:05,470 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:05,475 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:05,499 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:05,505 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,506 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,509 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:05,513 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:05,518 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,519 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,520 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:05,529 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:05,538 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:05,547 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:05,553 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,554 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,556 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:05,561 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:05,566 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,567 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,568 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:05,578 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:05,591 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:05,598 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:05,605 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,606 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,610 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:05,617 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:05,625 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,626 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,627 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:05,636 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:05,643 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:05,650 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:05,656 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,657 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,659 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:05,666 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:05,674 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,675 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,676 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:05,684 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:05,691 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:05,698 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:05,705 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,706 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,710 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:05,716 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:05,720 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,721 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,722 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:05,729 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:05,735 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:05,743 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:05,820 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,821 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,823 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:05,829 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:05,834 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,835 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,836 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:05,852 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:05,858 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:05,864 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:05,870 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,871 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,874 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:05,879 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:05,885 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,885 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,886 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:05,893 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:05,902 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:05,907 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:05,913 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,914 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,916 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:05,921 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:05,927 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,928 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,929 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:05,935 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:05,941 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:05,946 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:05,957 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:05,958 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:05,961 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:05,965 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:05,970 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:05,971 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:05,972 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:05,983 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:05,988 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:05,994 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:05,999 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:06,000 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,002 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:06,007 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:06,012 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,013 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,014 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:06,022 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:06,028 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:06,033 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:06,039 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:06,040 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,043 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:06,048 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:06,050 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,051 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 16])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 15, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,051 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:06,058 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:06,063 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:06,068 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:06,074 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"))\n",
      "2023-10-11 12:36:06,075 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,077 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:06,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:06,081 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,082 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:06,083 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:06,087 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:06,090 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:06,095 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:06,098 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:06,099 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,101 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:06,103 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:06,104 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,105 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:06,106 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:06,118 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:06,128 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:06,140 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:06,152 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:06,154 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,161 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:06,163 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:06,165 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:06,166 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:06,167 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:06,169 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:06,170 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:06,172 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:06,173 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:06,174 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,175 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:06,177 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:06,182 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 17])\", \"<class 'int'>: 16\")\n",
      "2023-10-11 12:36:06,183 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:06,184 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:06,186 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:06,188 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:06,189 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:06,191 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:06,192 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,197 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:06,202 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:06,207 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,208 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,209 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:06,215 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:06,221 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:06,225 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:06,230 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,231 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,234 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:06,239 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:06,244 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,245 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,246 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:06,252 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:06,258 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:06,263 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:06,269 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,270 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,272 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:06,277 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:06,282 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,283 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,284 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:06,291 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:06,296 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:06,301 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:06,314 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,315 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,318 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:06,322 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:06,327 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,328 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,329 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:06,336 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:06,341 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:06,346 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:06,351 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,352 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,354 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:06,359 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:06,364 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,365 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,366 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:06,380 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:06,385 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:06,400 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:06,410 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,410 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,413 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:06,417 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:06,422 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,422 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,423 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:06,430 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:06,435 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:06,442 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:06,447 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,448 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,451 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:06,455 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:06,460 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,461 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,462 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:06,469 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:06,474 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:06,479 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:06,488 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,489 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,492 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:06,497 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:06,502 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,503 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,504 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:06,510 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:06,519 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:06,536 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:06,575 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,576 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,579 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:06,584 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:06,588 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,590 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,591 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:06,619 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:06,658 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:06,715 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:06,757 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,758 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,761 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:06,765 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:06,769 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,770 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,771 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:06,796 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:06,802 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:06,808 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:06,876 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,877 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,879 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:06,884 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:06,889 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,891 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,892 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:06,899 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:06,904 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:06,910 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:06,915 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,916 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,918 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:06,923 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:06,925 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,925 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 17])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 16, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:06,926 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:06,933 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:06,951 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:06,957 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:06,964 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"))\n",
      "2023-10-11 12:36:06,965 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,967 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:06,969 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:06,970 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,971 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:06,972 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:06,974 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:06,976 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:06,978 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:06,980 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:06,981 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:06,983 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:06,984 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:06,985 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:06,986 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:06,987 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:07,002 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:07,014 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:07,027 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:07,037 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:07,039 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,046 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:07,047 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:07,049 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:07,049 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:07,050 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:07,052 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:07,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:07,056 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:07,057 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:07,058 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,059 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:07,061 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:07,066 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 18])\", \"<class 'int'>: 17\")\n",
      "2023-10-11 12:36:07,067 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:07,067 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:07,070 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:07,071 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:07,073 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:07,075 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:07,076 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:07,085 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:07,090 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,091 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,092 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:07,099 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:07,104 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:07,109 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:07,114 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,115 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,118 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:07,122 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:07,127 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,128 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,129 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:07,135 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:07,144 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:07,150 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:07,156 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,157 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,159 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:07,164 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:07,169 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,170 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,172 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:07,179 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:07,185 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:07,190 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:07,196 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,197 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,199 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:07,204 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:07,209 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,210 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,211 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:07,220 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:07,289 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:07,312 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:07,327 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,329 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,332 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:07,336 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:07,341 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,342 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,343 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:07,351 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:07,357 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:07,366 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:07,372 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,373 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,375 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:07,380 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:07,385 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,386 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,387 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:07,394 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:07,400 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:07,406 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:07,413 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,414 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,417 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:07,421 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:07,426 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,427 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,428 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:07,438 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:07,446 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:07,452 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:07,460 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,461 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,464 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:07,468 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:07,473 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,473 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,474 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:07,485 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:07,491 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:07,496 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:07,519 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,520 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,523 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:07,528 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:07,533 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,534 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,535 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:07,541 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:07,547 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:07,552 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:07,563 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,564 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,566 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:07,571 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:07,576 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,577 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,578 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:07,585 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:07,591 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:07,597 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:07,602 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,604 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,607 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:07,611 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:07,616 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,617 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,618 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:07,626 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:07,631 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:07,637 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:07,686 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,687 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,690 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:07,695 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:07,696 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,697 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 18])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 17, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,698 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:07,737 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:07,764 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:07,770 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:07,775 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"))\n",
      "2023-10-11 12:36:07,776 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,779 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:07,780 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:07,781 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,782 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:07,783 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:07,785 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:07,787 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:07,789 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:07,791 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:07,792 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,793 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:07,794 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:07,795 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,796 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:07,798 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:07,809 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:07,822 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:07,836 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:07,847 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:07,848 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,856 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:07,857 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:07,859 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:07,859 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:07,860 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:07,862 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:07,863 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:07,865 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:07,866 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:07,868 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,869 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:07,870 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:07,875 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 19])\", \"<class 'int'>: 18\")\n",
      "2023-10-11 12:36:07,875 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:07,877 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:07,878 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:07,880 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:07,882 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:07,884 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:07,884 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,889 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:07,893 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:07,899 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,899 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,900 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:07,907 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:07,912 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:07,918 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:07,923 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:07,924 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,926 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:07,931 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:07,936 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,937 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,938 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:07,950 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:07,955 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:07,961 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:07,966 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:07,967 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:07,969 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:07,974 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:07,979 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:07,980 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:07,981 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:07,989 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:07,995 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:08,001 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:08,008 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,009 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,012 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:08,017 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:08,021 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,022 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,023 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:08,030 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:08,035 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:08,040 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:08,046 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,046 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,049 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:08,054 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:08,059 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,060 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,061 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:08,068 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:08,073 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:08,079 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:08,084 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,085 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,087 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:08,091 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:08,096 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,097 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,098 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:08,104 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:08,109 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:08,114 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:08,119 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,120 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,122 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:08,127 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:08,131 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,132 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,133 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:08,139 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:08,144 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:08,154 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:08,159 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,160 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,163 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:08,167 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:08,172 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,173 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,174 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:08,180 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:08,187 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:08,214 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:08,220 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,221 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,223 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:08,228 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:08,233 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,233 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,234 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:08,251 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:08,256 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:08,261 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:08,266 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,268 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,270 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:08,275 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:08,280 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,281 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,282 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:08,289 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:08,295 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:08,303 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:08,308 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,309 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,312 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:08,317 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:08,322 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,323 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,324 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:08,331 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:08,338 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:08,346 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:08,352 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,353 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,355 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:08,360 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:08,361 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,362 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 19])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 18, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,362 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:08,374 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:08,381 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:08,388 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:08,398 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"))\n",
      "2023-10-11 12:36:08,399 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,402 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:08,403 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:08,404 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,405 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:08,406 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:08,408 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:08,411 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:08,414 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:08,417 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:08,419 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,421 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:08,422 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:08,423 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,424 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:08,425 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:08,436 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:08,452 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:08,466 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:08,477 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:08,478 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,484 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:08,486 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:08,487 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:08,488 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:08,489 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:08,491 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:08,492 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:08,494 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:08,495 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:08,496 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,498 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:08,499 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:08,504 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 20])\", \"<class 'int'>: 19\")\n",
      "2023-10-11 12:36:08,505 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:08,505 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:08,507 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:08,509 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:08,511 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:08,512 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:08,513 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,518 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:08,523 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:08,528 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,529 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,531 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:08,537 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:08,543 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:08,548 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:08,555 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,555 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,558 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:08,563 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:08,568 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,569 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,569 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:08,576 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:08,582 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:08,587 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:08,594 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,595 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,597 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:08,602 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:08,608 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,609 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,610 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:08,621 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:08,630 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:08,636 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:08,642 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,642 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,645 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:08,649 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:08,654 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,655 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,656 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:08,662 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:08,667 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:08,672 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:08,681 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,682 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,684 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:08,689 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:08,695 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,696 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,697 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:08,704 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:08,715 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:08,736 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:08,742 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,743 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,746 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:08,750 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:08,755 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,756 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,757 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:08,763 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:08,770 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:08,776 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:08,786 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,787 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,790 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:08,796 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:08,801 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,802 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,803 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:08,810 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:08,820 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:08,827 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:08,835 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,836 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,840 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:08,847 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:08,854 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,855 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,856 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:08,865 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:08,873 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:08,892 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:08,898 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,899 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,901 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:08,906 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:08,911 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,912 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,913 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:08,920 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:08,925 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:08,930 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:08,935 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,936 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,939 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:08,943 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:08,948 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,949 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,950 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:08,958 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:08,964 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:08,970 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:08,976 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:08,977 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:08,980 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:08,984 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:08,990 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:08,991 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:08,992 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:09,001 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:09,008 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:09,014 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:09,020 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:09,020 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,023 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:09,028 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:09,030 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,031 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 20])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 19, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,032 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:09,038 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:09,044 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:09,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:09,060 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"))\n",
      "2023-10-11 12:36:09,061 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,064 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:09,065 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:09,067 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,067 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,068 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:09,070 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:09,072 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:09,074 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:09,077 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:09,078 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,079 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:09,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:09,082 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,082 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,083 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:09,096 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:09,105 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:09,115 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:09,125 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:09,127 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,133 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:09,134 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:09,135 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:09,136 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,137 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:09,139 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:09,141 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:09,142 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:09,144 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:09,144 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,146 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:09,148 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:09,153 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 21])\", \"<class 'int'>: 20\")\n",
      "2023-10-11 12:36:09,154 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,154 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:09,156 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:09,158 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:09,160 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:09,161 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:09,162 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,167 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:09,172 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:09,178 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,179 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,180 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:09,190 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:09,202 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:09,218 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:09,224 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,225 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,227 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:09,231 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:09,236 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,236 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,238 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:09,244 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:09,250 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:09,256 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:09,265 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,266 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,270 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:09,275 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:09,280 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,281 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,282 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:09,289 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:09,295 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:09,302 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:09,309 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,310 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,313 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:09,317 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:09,322 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,323 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,324 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:09,331 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:09,336 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:09,341 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:09,346 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,347 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,350 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:09,355 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:09,361 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,362 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,363 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:09,371 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:09,376 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:09,382 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:09,387 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,388 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,391 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:09,396 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:09,400 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,401 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,402 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:09,409 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:09,415 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:09,421 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:09,427 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,427 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,430 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:09,434 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:09,440 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,441 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,441 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:09,457 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:09,462 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:09,468 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:09,473 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,474 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,476 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:09,481 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:09,486 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,486 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,488 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:09,494 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:09,500 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:09,505 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:09,510 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,511 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,513 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:09,519 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:09,525 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,526 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,527 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:09,536 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:09,545 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:09,551 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:09,556 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,557 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,560 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:09,565 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:09,570 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,571 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,572 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:09,579 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:09,585 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:09,593 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:09,603 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,604 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,606 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:09,611 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:09,616 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,617 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,618 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:09,629 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:09,637 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:09,645 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:09,679 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,680 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,682 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:09,687 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:09,689 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,690 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 21])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 20, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,691 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:09,699 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:09,705 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:09,710 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:09,716 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"))\n",
      "2023-10-11 12:36:09,717 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,719 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:09,720 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:09,722 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,722 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,723 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:09,725 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:09,727 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:09,730 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:09,732 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:09,733 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,734 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:09,736 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:09,737 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,738 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,739 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:09,755 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:09,788 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:09,804 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:09,824 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:09,826 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,866 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:09,868 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:09,869 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:09,870 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,871 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:09,873 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:09,874 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:09,876 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:09,877 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:09,878 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,880 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:09,881 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:09,886 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 22])\", \"<class 'int'>: 21\")\n",
      "2023-10-11 12:36:09,887 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:09,888 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:09,890 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:09,891 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:09,893 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:09,894 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:09,895 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,900 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:09,905 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:09,910 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,911 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,912 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:09,919 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:09,924 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:09,930 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:09,935 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:09,935 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,938 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:09,943 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:09,947 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,948 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,949 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:09,956 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:09,962 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:09,969 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:09,975 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:09,976 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:09,978 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:09,983 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:09,988 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:09,989 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:09,989 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:09,998 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:10,015 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:10,020 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:10,027 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,028 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,031 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:10,035 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:10,040 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,041 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,042 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:10,049 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:10,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:10,059 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:10,064 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,064 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,067 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:10,072 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:10,077 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,078 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,078 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:10,085 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:10,090 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:10,097 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:10,102 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,103 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,106 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:10,111 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:10,115 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,116 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,117 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:10,123 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:10,129 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:10,134 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:10,147 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,147 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,150 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:10,154 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:10,159 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,159 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,160 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:10,167 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:10,172 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:10,177 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:10,182 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,183 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,185 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:10,189 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:10,194 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,194 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,195 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:10,202 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:10,208 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:10,223 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:10,231 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,232 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,235 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:10,239 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:10,245 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,246 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,247 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:10,261 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:10,269 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:10,275 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:10,283 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,284 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,286 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:10,291 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:10,296 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,297 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,298 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:10,305 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:10,311 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:10,316 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:10,323 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,324 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,326 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:10,331 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:10,337 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,337 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,338 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:10,345 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:10,354 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:10,361 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:10,367 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,368 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,371 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:10,376 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:10,377 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,378 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 22])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 21, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,379 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:10,391 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:10,402 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:10,407 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:10,412 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"))\n",
      "2023-10-11 12:36:10,413 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,416 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:10,417 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:10,418 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,419 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:10,420 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:10,423 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:10,425 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:10,427 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:10,430 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:10,431 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,432 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:10,433 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:10,435 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,435 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:10,436 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:10,455 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:10,466 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:10,481 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:10,490 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:10,492 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,501 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:10,502 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:10,504 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:10,505 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:10,506 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:10,508 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:10,510 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:10,511 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:10,513 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:10,513 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,515 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:10,517 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:10,522 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 23])\", \"<class 'int'>: 22\")\n",
      "2023-10-11 12:36:10,523 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:10,523 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:10,525 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:10,527 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:10,529 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:10,530 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:10,531 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,536 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:10,541 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:10,545 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,546 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,547 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:10,554 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:10,560 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:10,565 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:10,570 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,571 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,573 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:10,577 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:10,583 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,583 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,584 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:10,592 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:10,598 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:10,604 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:10,611 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,612 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,614 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:10,619 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:10,623 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,624 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,625 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:10,633 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:10,639 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:10,647 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:10,662 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,662 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,665 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:10,670 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:10,675 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,676 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,677 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:10,684 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:10,690 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:10,695 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:10,701 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,702 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,705 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:10,711 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:10,717 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,718 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,719 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:10,731 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:10,739 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:10,745 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:10,771 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,771 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,775 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:10,780 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:10,785 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,786 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,788 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:10,800 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:10,813 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:10,822 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:10,878 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,879 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,881 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:10,885 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:10,890 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,890 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,891 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:10,899 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:10,906 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:10,924 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:10,934 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,935 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,937 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:10,942 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:10,947 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,948 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,949 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:10,955 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:10,963 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:10,968 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:10,977 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:10,978 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:10,981 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:10,988 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:10,993 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:10,994 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:10,995 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:11,001 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:11,010 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:11,016 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:11,027 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:11,028 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,030 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:11,035 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:11,039 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,040 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,042 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:11,048 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:11,055 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:11,061 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:11,069 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:11,071 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,073 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:11,077 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:11,082 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,083 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,084 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:11,091 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:11,097 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:11,105 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:11,111 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:11,112 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,115 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:11,120 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:11,121 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,123 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 23])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 22, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,123 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:11,129 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:11,135 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:11,144 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:11,150 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"))\n",
      "2023-10-11 12:36:11,150 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,153 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:11,154 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:11,156 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,156 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:11,158 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:11,161 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:11,165 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:11,166 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:11,168 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:11,169 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,171 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:11,172 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:11,173 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,174 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:11,175 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:11,187 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:11,197 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:11,213 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:11,222 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:11,224 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,232 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:11,234 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:11,235 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:11,236 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:11,237 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:11,238 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:11,240 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:11,241 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:11,243 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:11,244 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,245 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:11,246 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:11,251 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 24])\", \"<class 'int'>: 23\")\n",
      "2023-10-11 12:36:11,252 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:11,252 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:11,254 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:11,256 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:11,258 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:11,259 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:11,260 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,264 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:11,269 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:11,273 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,274 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,275 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:11,282 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:11,288 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:11,293 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:11,298 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,299 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,301 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:11,305 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:11,310 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,311 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,312 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:11,319 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:11,330 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:11,347 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:11,354 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,355 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,358 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:11,362 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:11,367 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,368 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,369 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:11,437 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:11,444 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:11,455 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:11,460 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,461 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,464 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:11,468 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:11,473 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,474 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,475 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:11,482 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:11,488 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:11,493 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:11,508 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,509 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,513 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:11,518 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:11,524 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,525 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,525 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:11,532 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:11,543 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:11,549 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:11,558 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,559 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,561 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:11,565 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:11,570 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,571 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,572 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:11,582 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:11,589 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:11,594 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:11,599 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,600 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,602 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:11,607 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:11,612 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,613 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,613 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:11,620 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:11,626 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:11,633 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:11,638 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,639 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,641 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:11,646 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:11,651 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,652 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,652 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:11,659 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:11,665 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:11,671 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:11,678 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,679 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,681 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:11,686 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:11,691 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,692 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,692 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:11,700 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:11,767 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:11,782 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:11,788 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,789 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,792 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:11,797 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:11,803 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,804 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,805 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:11,815 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:11,821 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:11,831 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:11,836 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,837 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,840 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:11,844 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:11,849 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,850 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,851 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:11,857 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:11,869 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:11,878 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:11,886 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,887 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,889 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:11,894 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:11,895 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,896 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 24])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 23, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:11,897 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:11,903 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:11,910 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:11,916 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:11,922 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"))\n",
      "2023-10-11 12:36:11,924 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,926 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:11,928 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:11,930 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,931 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:11,931 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:11,934 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:11,937 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:11,939 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:11,943 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:11,944 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:11,945 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:11,946 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:11,948 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:11,949 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:11,949 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:11,966 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:11,980 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:11,990 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:12,004 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:12,006 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,014 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:12,016 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:12,017 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:12,018 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:12,019 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:12,021 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:12,023 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:12,024 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:12,025 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:12,026 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,028 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:12,029 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:12,034 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 25])\", \"<class 'int'>: 24\")\n",
      "2023-10-11 12:36:12,034 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:12,035 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:12,038 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:12,040 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:12,041 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:12,043 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:12,044 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,048 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:12,053 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:12,057 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,058 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,059 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:12,065 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:12,078 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:12,083 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:12,088 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,089 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,092 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:12,096 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:12,101 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,102 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,103 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:12,110 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:12,116 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:12,121 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:12,127 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,128 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,131 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:12,135 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:12,140 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,141 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,141 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:12,159 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:12,179 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:12,187 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:12,193 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,194 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,196 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:12,201 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:12,206 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,207 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,207 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:12,214 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:12,221 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:12,227 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:12,232 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,233 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,235 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:12,240 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:12,245 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,246 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,246 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:12,253 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:12,267 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:12,272 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:12,283 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,284 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,286 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:12,291 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:12,296 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,296 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,297 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:12,304 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:12,309 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:12,314 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:12,320 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,320 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,323 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:12,327 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:12,332 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,333 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,334 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:12,346 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:12,352 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:12,358 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:12,381 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,382 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,384 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:12,389 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:12,394 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,395 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,396 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:12,403 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:12,408 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:12,416 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:12,421 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,422 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,424 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:12,429 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:12,434 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,436 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,436 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:12,519 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:12,529 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:12,535 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:12,541 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,542 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,544 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:12,549 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:12,553 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,554 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,555 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:12,562 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:12,569 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:12,574 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:12,580 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,581 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,583 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:12,588 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:12,593 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,594 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,595 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:12,602 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:12,607 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:12,618 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:12,624 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,625 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,628 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:12,633 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:12,634 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,635 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 25])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 24, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,636 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:12,642 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:12,648 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:12,653 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:12,659 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"))\n",
      "2023-10-11 12:36:12,660 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,662 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:12,663 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:12,664 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,665 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:12,666 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:12,669 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:12,673 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:12,675 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:12,677 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:12,678 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,679 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:12,680 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:12,681 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,682 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:12,683 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:12,694 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:12,708 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:12,721 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:12,731 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:12,732 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,740 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:12,741 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:12,743 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:12,744 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:12,744 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:12,746 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:12,748 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:12,749 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:12,751 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:12,752 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,753 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:12,754 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:12,759 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 26])\", \"<class 'int'>: 25\")\n",
      "2023-10-11 12:36:12,760 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:12,761 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:12,763 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:12,765 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:12,767 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:12,768 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:12,769 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,773 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:12,778 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:12,783 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,783 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,784 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:12,795 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:12,803 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:12,812 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:12,817 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:12,818 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,820 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:12,825 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:12,830 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,831 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,831 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:12,840 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:12,849 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:12,854 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:12,859 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:12,861 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,863 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:12,867 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:12,872 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,873 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,874 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:12,887 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:12,896 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:12,902 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:12,910 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:12,911 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:12,913 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:12,919 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:12,923 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:12,924 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:12,925 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:12,931 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:13,001 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:13,019 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:13,034 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,035 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,038 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:13,042 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:13,047 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,048 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,049 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:13,059 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:13,065 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:13,071 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:13,077 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,078 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,080 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:13,085 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:13,090 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,090 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,091 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:13,099 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:13,105 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:13,111 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:13,117 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,118 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,121 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:13,126 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:13,131 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,132 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,133 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:13,140 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:13,147 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:13,152 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:13,158 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,159 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,161 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:13,165 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:13,170 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,171 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,171 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:13,179 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:13,185 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:13,191 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:13,196 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,197 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,199 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:13,204 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:13,209 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,210 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,211 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:13,217 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:13,225 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:13,230 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:13,236 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,237 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,240 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:13,244 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:13,251 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,256 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,257 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:13,309 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:13,329 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:13,358 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:13,364 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,365 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,368 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:13,372 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:13,377 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,378 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,379 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:13,388 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:13,399 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:13,405 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:13,411 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,412 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,414 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:13,419 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:13,421 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,421 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 26])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 25, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,422 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:13,429 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:13,435 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:13,445 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:13,450 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"))\n",
      "2023-10-11 12:36:13,451 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,453 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:13,455 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:13,456 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,457 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:13,458 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:13,462 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:13,467 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:13,469 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:13,473 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:13,475 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,476 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:13,477 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:13,479 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,479 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:13,480 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:13,496 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:13,507 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:13,519 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:13,530 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:13,532 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,540 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:13,542 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:13,544 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:13,545 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:13,545 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:13,547 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:13,548 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:13,550 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:13,551 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:13,552 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,553 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:13,555 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:13,559 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 27])\", \"<class 'int'>: 26\")\n",
      "2023-10-11 12:36:13,560 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:13,561 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:13,563 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:13,565 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:13,567 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:13,569 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:13,570 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,575 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:13,580 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:13,585 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,586 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,587 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:13,594 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:13,600 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:13,615 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:13,621 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:13,622 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,624 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:13,629 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:13,634 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,635 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,636 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:13,648 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:13,654 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:13,660 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:13,667 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:13,667 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,670 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:13,675 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:13,681 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,682 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,682 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:13,691 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:13,697 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:13,703 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:13,745 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:13,747 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,749 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:13,755 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:13,760 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,761 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,761 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:13,818 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:13,873 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:13,914 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:13,927 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:13,928 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,931 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:13,935 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:13,941 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,942 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,943 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:13,950 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:13,955 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:13,962 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:13,982 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:13,982 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:13,985 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:13,989 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:13,994 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:13,994 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:13,995 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:14,002 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:14,010 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:14,015 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:14,021 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,022 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,025 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:14,030 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:14,035 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,036 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,037 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:14,044 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:14,109 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:14,147 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:14,152 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,153 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,156 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:14,161 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:14,166 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,167 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,168 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:14,176 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:14,181 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:14,187 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:14,194 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,195 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,197 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:14,202 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:14,207 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,208 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,209 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:14,216 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:14,222 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:14,228 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:14,237 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,238 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,240 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:14,245 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:14,250 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,251 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,252 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:14,261 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:14,270 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:14,276 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:14,281 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,282 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,284 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:14,288 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:14,293 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,294 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,294 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:14,304 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:14,312 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:14,334 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:14,340 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,341 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,343 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:14,348 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:14,349 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,350 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 27])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 26, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,351 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:14,364 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:14,381 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:14,436 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:14,450 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"))\n",
      "2023-10-11 12:36:14,451 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,454 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:14,455 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:14,456 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,457 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:14,458 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:14,461 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:14,464 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:14,466 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:14,468 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:14,469 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,470 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:14,472 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:14,473 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,474 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:14,475 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:14,485 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:14,497 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:14,510 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:14,524 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:14,526 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,536 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:14,538 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:14,539 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:14,540 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:14,541 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:14,543 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:14,544 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:14,546 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:14,547 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:14,548 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,550 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:14,551 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:14,556 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 28])\", \"<class 'int'>: 27\")\n",
      "2023-10-11 12:36:14,556 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:14,557 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:14,559 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:14,561 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:14,562 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:14,564 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:14,564 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,569 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:14,573 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:14,578 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,579 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,580 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:14,587 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:14,594 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:14,599 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:14,606 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,606 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,609 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:14,614 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:14,618 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,619 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,620 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:14,626 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:14,634 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:14,640 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:14,645 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,646 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,649 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:14,654 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:14,659 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,660 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,661 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:14,668 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:14,675 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:14,681 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:14,687 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,687 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,690 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:14,695 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:14,700 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,701 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,702 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:14,708 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:14,715 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:14,720 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:14,726 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,727 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,729 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:14,734 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:14,739 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,740 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,740 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:14,750 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:14,755 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:14,761 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:14,766 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,767 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,769 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:14,774 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:14,779 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,780 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,781 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:14,787 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:14,795 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:14,804 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:14,812 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,813 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,816 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:14,822 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:14,828 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,830 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,830 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:14,837 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:14,842 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:14,849 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:14,882 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:14,883 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:14,885 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:14,890 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:14,895 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:14,896 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:14,896 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:14,904 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:14,911 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:14,931 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:15,012 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:15,014 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,017 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:15,022 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:15,027 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,028 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,029 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:15,040 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:15,046 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:15,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:15,061 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:15,062 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,065 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:15,070 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:15,075 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,076 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,077 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:15,092 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:15,098 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:15,104 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:15,114 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:15,115 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,117 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:15,122 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:15,129 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,130 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,131 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:15,142 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:15,217 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:15,224 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:15,231 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:15,231 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,234 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:15,239 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:15,240 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,242 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 28])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 27, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,245 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:15,257 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:15,273 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:15,280 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:15,290 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"))\n",
      "2023-10-11 12:36:15,291 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,293 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:15,295 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:15,297 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,298 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:15,298 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:15,303 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:15,306 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:15,309 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:15,312 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:15,313 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,314 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:15,315 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:15,316 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,317 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:15,318 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:15,332 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:15,342 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:15,352 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:15,362 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:15,364 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,373 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:15,374 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:15,376 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:15,377 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:15,378 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:15,380 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:15,381 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:15,383 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:15,385 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:15,385 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,387 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:15,388 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:15,393 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 29])\", \"<class 'int'>: 28\")\n",
      "2023-10-11 12:36:15,393 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:15,395 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:15,396 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:15,398 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:15,400 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:15,401 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:15,402 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,407 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:15,411 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:15,416 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,417 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,418 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:15,424 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:15,431 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:15,438 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:15,445 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,446 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,448 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:15,453 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:15,458 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,459 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,459 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:15,469 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:15,478 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:15,484 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:15,491 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,492 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,494 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:15,499 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:15,504 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,505 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,506 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:15,515 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:15,523 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:15,530 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:15,609 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,611 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,613 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:15,618 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:15,623 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,624 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,625 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:15,632 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:15,638 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:15,645 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:15,651 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,652 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,654 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:15,659 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:15,664 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,664 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,665 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:15,672 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:15,681 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:15,687 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:15,692 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,693 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,696 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:15,701 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:15,706 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,707 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,708 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:15,722 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:15,728 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:15,733 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:15,749 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,750 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,752 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:15,757 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:15,761 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,762 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,763 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:15,772 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:15,780 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:15,788 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:15,793 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,794 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:15,797 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:15,801 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:15,806 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:15,807 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:15,808 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:15,881 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:15,966 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:15,990 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:15,998 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:15,999 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,001 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:16,006 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:16,012 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,013 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,014 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:16,021 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:16,030 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:16,038 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:16,044 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:16,044 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,047 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:16,051 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:16,056 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,057 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,058 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:16,064 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:16,071 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:16,076 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:16,082 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:16,083 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,085 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:16,090 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:16,095 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,095 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,096 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:16,131 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:16,183 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:16,234 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:16,259 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:16,260 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,262 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:16,267 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:16,268 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,270 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 29])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 28, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,271 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:16,279 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:16,285 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:16,291 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:16,297 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"))\n",
      "2023-10-11 12:36:16,298 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,300 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:16,302 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:16,303 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,304 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:16,305 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:16,307 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:16,310 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:16,311 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:16,314 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:16,315 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,316 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:16,317 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:16,319 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,319 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:16,320 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:16,331 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:16,345 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:16,356 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:16,371 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:16,372 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,381 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:16,383 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:16,384 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:16,385 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:16,386 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:16,388 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:16,390 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:16,391 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:16,392 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:16,393 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,394 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:16,396 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:16,401 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 30])\", \"<class 'int'>: 29\")\n",
      "2023-10-11 12:36:16,401 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:16,402 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:16,404 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:16,406 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:16,408 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:16,410 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:16,411 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,415 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:16,419 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:16,424 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,424 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,425 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:16,433 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:16,442 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:16,448 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:16,456 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,456 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,459 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:16,463 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:16,467 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,468 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,469 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:16,475 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:16,560 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:16,620 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:16,672 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,673 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,675 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:16,680 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:16,684 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,685 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,692 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:16,766 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:16,783 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:16,788 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:16,795 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,796 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,798 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:16,803 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:16,807 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,808 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,809 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:16,816 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:16,824 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:16,830 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:16,836 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,837 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,839 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:16,843 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:16,848 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,849 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,850 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:16,857 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:16,874 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:16,882 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:16,888 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,889 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,891 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:16,895 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:16,900 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,901 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,902 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:16,927 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:16,936 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:16,942 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:16,948 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,949 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:16,952 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:16,956 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:16,962 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:16,963 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:16,964 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:16,971 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:16,985 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:16,992 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:16,998 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:16,999 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,001 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:17,005 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:17,010 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,011 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,012 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:17,019 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:17,024 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:17,031 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:17,037 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:17,037 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,040 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:17,044 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:17,049 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,050 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,050 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:17,057 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:17,063 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:17,069 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:17,076 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:17,077 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,079 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:17,083 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:17,088 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,088 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,090 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:17,097 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:17,106 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:17,118 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:17,127 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:17,128 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,130 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:17,134 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:17,139 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,140 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,141 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:17,149 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:17,157 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:17,164 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:17,172 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:17,173 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,175 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:17,180 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:17,181 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,182 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 30])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 29, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,183 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:17,189 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:17,195 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:17,273 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:17,284 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"))\n",
      "2023-10-11 12:36:17,285 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,288 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:17,290 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:17,292 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,292 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:17,293 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:17,297 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:17,300 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:17,302 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:17,304 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:17,305 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,306 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:17,308 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:17,310 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,311 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:17,312 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:17,330 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:17,342 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:17,353 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:17,366 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:17,367 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,381 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:17,382 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:17,384 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:17,385 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:17,386 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:17,388 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:17,389 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:17,391 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:17,392 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:17,393 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,394 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:17,395 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:17,400 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 31])\", \"<class 'int'>: 30\")\n",
      "2023-10-11 12:36:17,401 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:17,402 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:17,404 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:17,405 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:17,407 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:17,409 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:17,410 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,414 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:17,419 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:17,424 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,425 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,425 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:17,434 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:17,450 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:17,457 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:17,466 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,467 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,470 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:17,474 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:17,479 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,480 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,480 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:17,487 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:17,494 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:17,500 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:17,512 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,513 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,515 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:17,519 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:17,525 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,526 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,527 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:17,607 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:17,614 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:17,620 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:17,626 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,627 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,629 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:17,634 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:17,638 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,639 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,640 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:17,647 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:17,666 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:17,672 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:17,678 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,679 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,681 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:17,686 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:17,692 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,693 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,693 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:17,701 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:17,707 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:17,713 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:17,719 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,720 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,722 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:17,727 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:17,732 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,733 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,734 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:17,742 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:17,748 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:17,754 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:17,760 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,761 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,764 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:17,768 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:17,773 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,774 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,775 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:17,784 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:17,790 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:17,795 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:17,801 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,802 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,804 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:17,809 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:17,814 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,814 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,816 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:17,824 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:17,832 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:17,839 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:17,845 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,846 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,848 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:17,853 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:17,858 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,859 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,860 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:17,867 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:17,873 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:17,879 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:17,884 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,885 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,888 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:17,892 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:17,897 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,898 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,899 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:17,906 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:17,911 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:17,922 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:17,927 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,928 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,930 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:17,935 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:17,940 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,941 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,941 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:17,948 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:17,954 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:17,960 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:17,967 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:17,968 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:17,970 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:17,975 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:17,976 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:17,977 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 31])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 30, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:17,978 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:17,986 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:17,995 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:18,003 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:18,008 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"))\n",
      "2023-10-11 12:36:18,009 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,012 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:18,013 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:18,015 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,016 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:18,017 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:18,021 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:18,025 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:18,027 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:18,030 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:18,031 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,032 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:18,034 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:18,035 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,036 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:18,037 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:18,047 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:18,061 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:18,075 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:18,085 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:18,086 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,101 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:18,103 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:18,104 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:18,105 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:18,106 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:18,107 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:18,110 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:18,112 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:18,114 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:18,119 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,120 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:18,125 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:18,131 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 32])\", \"<class 'int'>: 31\")\n",
      "2023-10-11 12:36:18,131 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:18,132 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:18,135 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:18,136 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:18,138 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:18,141 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:18,142 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,147 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:18,152 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:18,157 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,158 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,159 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:18,212 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:18,220 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:18,228 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:18,295 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,297 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,300 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:18,305 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:18,310 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,311 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,312 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:18,322 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:18,333 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:18,341 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:18,347 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,348 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,351 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:18,355 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:18,361 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,362 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,363 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:18,372 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:18,384 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:18,392 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:18,460 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,461 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,464 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:18,468 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:18,473 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,474 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,475 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:18,482 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:18,488 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:18,495 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:18,501 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,502 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,504 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:18,509 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:18,514 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,515 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,515 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:18,524 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:18,530 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:18,537 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:18,543 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,543 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,546 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:18,551 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:18,556 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,557 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,558 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:18,573 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:18,587 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:18,594 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:18,600 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,601 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,603 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:18,608 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:18,613 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,614 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,614 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:18,622 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:18,631 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:18,638 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:18,647 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,648 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,651 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:18,655 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:18,660 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,661 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,662 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:18,669 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:18,679 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:18,688 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:18,694 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,695 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,697 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:18,702 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:18,707 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,708 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,708 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:18,717 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:18,723 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:18,729 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:18,793 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,795 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,797 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:18,802 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:18,807 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,808 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,809 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:18,818 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:18,827 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:18,835 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:18,841 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,842 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,844 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:18,850 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:18,855 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,856 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,857 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:18,866 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:18,877 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:18,883 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:18,891 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,892 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,895 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:18,900 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:18,901 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,902 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 32])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 31, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:18,904 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:18,912 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:18,922 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:18,928 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:18,934 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"))\n",
      "2023-10-11 12:36:18,935 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,937 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:18,939 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:18,940 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,941 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:18,942 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:18,944 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:18,945 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:18,947 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:18,949 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:18,950 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:18,951 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:18,953 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:18,954 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:18,955 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:18,955 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:18,971 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:18,981 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:18,991 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:19,002 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:19,003 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,011 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:19,013 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:19,014 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:19,014 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:19,015 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:19,017 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:19,018 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:19,020 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:19,022 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:19,022 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,024 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:19,025 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:19,030 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 33])\", \"<class 'int'>: 32\")\n",
      "2023-10-11 12:36:19,031 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:19,032 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:19,033 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:19,035 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:19,037 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:19,038 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:19,039 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,043 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:19,047 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:19,052 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,053 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:19,060 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:19,080 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:19,093 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:19,103 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,104 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,106 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:19,112 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:19,119 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,120 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,121 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:19,132 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:19,160 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:19,236 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:19,263 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,264 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,266 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:19,270 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:19,274 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,275 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,276 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:19,293 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:19,302 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:19,308 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:19,317 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,318 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,321 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:19,326 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:19,331 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,332 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,333 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:19,404 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:19,412 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:19,418 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:19,423 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,424 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,427 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:19,431 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:19,436 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,437 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,438 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:19,445 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:19,451 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:19,457 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:19,463 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,464 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,468 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:19,473 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:19,478 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,479 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,480 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:19,487 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:19,493 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:19,498 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:19,506 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,507 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,509 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:19,514 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:19,519 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,520 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,522 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:19,530 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:19,536 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:19,541 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:19,548 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,549 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,551 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:19,556 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:19,560 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,561 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,562 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:19,570 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:19,601 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:19,607 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:19,616 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,616 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,619 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:19,623 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:19,627 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,628 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,629 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:19,636 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:19,643 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:19,650 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:19,659 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,660 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,662 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:19,666 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:19,671 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,672 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,673 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:19,679 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:19,685 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:19,691 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:19,699 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,700 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,702 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:19,706 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:19,711 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,712 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,713 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:19,720 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:19,727 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:19,734 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:19,742 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,743 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,745 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:19,749 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:19,751 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,751 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 33])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 32, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,752 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:19,758 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:19,765 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:19,773 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:19,778 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"))\n",
      "2023-10-11 12:36:19,779 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,781 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:19,782 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:19,783 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,784 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:19,785 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:19,789 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:19,790 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:19,792 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:19,794 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:19,795 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,797 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:19,798 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:19,799 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,800 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:19,801 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:19,814 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:19,828 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:19,840 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:19,855 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:19,856 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,865 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:19,867 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:19,868 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:19,869 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:19,870 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:19,871 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:19,873 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:19,874 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:19,876 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:19,876 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,878 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:19,879 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:19,884 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 34])\", \"<class 'int'>: 33\")\n",
      "2023-10-11 12:36:19,885 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:19,886 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:19,888 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:19,889 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:19,891 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:19,892 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:19,893 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,897 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:19,902 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:19,907 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,908 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,909 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:19,915 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:19,922 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:19,927 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:19,933 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:19,934 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,937 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:19,941 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:19,945 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,946 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,947 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:19,954 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:19,962 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:19,968 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:19,973 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:19,974 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:19,977 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:19,981 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:19,986 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:19,986 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:19,987 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:19,994 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:20,000 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:20,008 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:20,014 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,015 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,017 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:20,022 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:20,026 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,027 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,028 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:20,035 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:20,041 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:20,047 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:20,052 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,053 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,055 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:20,060 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:20,064 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,065 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,066 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:20,076 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:20,082 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:20,101 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:20,107 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,108 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,111 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:20,115 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:20,120 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,121 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,122 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:20,129 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:20,135 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:20,141 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:20,150 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,151 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,154 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:20,158 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:20,164 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,165 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,167 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:20,181 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:20,188 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:20,194 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:20,201 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,202 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,205 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:20,210 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:20,216 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,217 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,218 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:20,227 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:20,233 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:20,239 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:20,245 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,246 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,248 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:20,253 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:20,258 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,258 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,260 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:20,266 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:20,274 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:20,280 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:20,287 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,288 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,291 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:20,295 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:20,300 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,301 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,302 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:20,336 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:20,343 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:20,349 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:20,359 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,360 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,362 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:20,367 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:20,372 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,373 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,374 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:20,388 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:20,395 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:20,400 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:20,411 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,411 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,414 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:20,420 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:20,421 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,422 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 34])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 33, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,424 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:20,431 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:20,437 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:20,450 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:20,456 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"))\n",
      "2023-10-11 12:36:20,457 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,460 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:20,461 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:20,463 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,464 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:20,465 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:20,483 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:20,488 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:20,492 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:20,500 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:20,502 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,504 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:20,505 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:20,509 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,510 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:20,511 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:20,534 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:20,546 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:20,558 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:20,569 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:20,571 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,585 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:20,586 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:20,588 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:20,589 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:20,590 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:20,592 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:20,593 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:20,604 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:20,606 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:20,607 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,608 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:20,610 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:20,615 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 35])\", \"<class 'int'>: 34\")\n",
      "2023-10-11 12:36:20,616 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:20,617 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:20,619 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:20,621 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:20,623 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:20,624 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:20,625 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,631 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:20,635 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:20,640 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,641 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,642 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:20,656 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:20,702 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:20,711 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:20,719 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:20,719 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,722 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:20,726 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:20,730 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,731 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,732 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:20,739 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:20,745 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:20,751 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:20,816 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:20,817 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,819 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:20,824 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:20,829 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,830 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,830 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:20,865 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:20,876 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:20,894 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:20,900 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:20,901 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:20,904 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:20,908 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:20,913 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:20,914 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:20,914 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:20,990 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:20,998 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:21,010 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:21,016 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,017 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,020 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:21,026 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:21,032 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,033 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,034 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:21,041 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:21,050 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:21,056 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:21,062 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,063 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,066 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:21,070 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:21,075 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,075 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,076 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:21,087 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:21,094 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:21,100 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:21,106 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,107 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,109 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:21,114 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:21,119 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,120 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,120 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:21,129 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:21,134 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:21,141 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:21,150 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,151 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,154 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:21,158 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:21,163 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,163 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,164 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:21,172 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:21,182 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:21,195 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:21,200 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,201 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,203 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:21,209 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:21,214 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,215 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,215 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:21,224 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:21,233 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:21,240 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:21,247 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,248 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,250 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:21,255 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:21,260 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,261 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,262 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:21,273 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:21,280 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:21,286 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:21,291 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,292 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,295 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:21,299 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:21,304 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,305 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,305 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:21,312 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:21,318 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:21,325 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:21,333 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,334 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,336 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:21,340 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:21,342 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,343 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 35])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 34, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,344 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:21,350 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:21,357 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:21,363 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:21,369 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"))\n",
      "2023-10-11 12:36:21,370 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,372 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:21,374 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:21,375 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,376 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:21,377 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:21,381 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:21,383 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:21,385 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:21,389 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:21,390 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,391 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:21,393 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:21,394 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,395 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:21,396 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:21,411 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:21,421 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:21,430 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:21,440 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:21,441 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,448 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:21,450 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:21,451 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:21,451 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:21,452 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:21,454 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:21,455 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:21,457 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:21,458 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:21,459 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,461 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:21,462 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:21,467 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 36])\", \"<class 'int'>: 35\")\n",
      "2023-10-11 12:36:21,468 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:21,469 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:21,471 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:21,473 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:21,474 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:21,476 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:21,476 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,480 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:21,484 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:21,489 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,490 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,491 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:21,565 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:21,597 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:21,622 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:21,629 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,630 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,633 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:21,637 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:21,643 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,644 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,645 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:21,660 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:21,677 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:21,688 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:21,698 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,699 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,702 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:21,706 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:21,711 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,712 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,713 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:21,721 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:21,727 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:21,732 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:21,738 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,739 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,741 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:21,746 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:21,750 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,751 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,752 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:21,759 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:21,765 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:21,774 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:21,781 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,782 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,784 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:21,788 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:21,792 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,793 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,794 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:21,805 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:21,814 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:21,823 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:21,829 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,830 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,832 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:21,836 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:21,841 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,842 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,843 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:21,852 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:21,859 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:21,866 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:21,871 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,872 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,875 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:21,879 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:21,884 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,885 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,885 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:21,895 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:21,900 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:21,907 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:21,913 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,913 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,916 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:21,921 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:21,925 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,926 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,927 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:21,943 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:21,964 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:21,971 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:21,978 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:21,979 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:21,981 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:21,986 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:21,991 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:21,992 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:21,993 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:22,003 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:22,015 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:22,033 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:22,040 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:22,040 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,043 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:22,048 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:22,053 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,054 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,054 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:22,061 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:22,066 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:22,078 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:22,165 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:22,166 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,168 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:22,173 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:22,179 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,180 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,181 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:22,188 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:22,197 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:22,273 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:22,301 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:22,302 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,305 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:22,310 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:22,312 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,313 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 36])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 35, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,314 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:22,323 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:22,331 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:22,337 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:22,344 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"))\n",
      "2023-10-11 12:36:22,345 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,348 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:22,349 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:22,351 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,351 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:22,352 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:22,354 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:22,357 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:22,360 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:22,363 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:22,364 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,366 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:22,368 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:22,369 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,370 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:22,371 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:22,384 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:22,397 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:22,408 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:22,418 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:22,420 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,428 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:22,429 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:22,431 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:22,432 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:22,433 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:22,434 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:22,436 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:22,437 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:22,439 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:22,440 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,441 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:22,443 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:22,447 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 37])\", \"<class 'int'>: 36\")\n",
      "2023-10-11 12:36:22,448 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:22,449 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:22,451 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:22,452 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:22,454 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:22,456 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:22,457 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,461 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:22,465 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:22,470 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,471 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,472 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:22,481 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:22,492 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:22,499 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:22,507 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,508 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,510 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:22,515 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:22,520 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,521 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,523 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:22,536 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:22,545 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:22,552 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:22,558 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,559 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,561 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:22,566 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:22,571 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,572 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,573 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:22,580 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:22,652 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:22,682 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:22,689 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,690 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,693 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:22,698 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:22,703 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,704 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,705 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:22,715 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:22,723 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:22,729 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:22,801 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,802 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,805 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:22,809 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:22,814 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,815 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,816 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:22,823 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:22,835 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:22,841 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:22,847 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,848 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,851 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:22,855 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:22,860 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,860 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,861 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:22,874 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:22,880 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:22,886 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:22,892 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,892 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,894 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:22,899 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:22,904 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,904 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,906 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:22,912 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:22,917 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:22,923 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:22,931 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,932 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,934 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:22,939 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:22,944 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,945 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,946 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:22,953 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:22,960 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:22,969 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:22,975 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:22,975 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:22,978 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:22,982 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:22,987 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:22,988 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:22,989 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:22,996 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:23,003 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:23,010 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:23,016 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:23,018 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,020 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:23,025 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:23,030 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,031 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,031 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:23,038 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:23,052 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:23,062 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:23,067 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:23,068 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,071 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:23,076 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:23,081 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,081 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,082 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:23,090 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:23,096 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:23,103 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:23,182 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:23,184 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,186 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:23,191 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:23,193 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,194 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 37])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 36, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,194 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:23,224 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:23,271 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:23,315 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:23,323 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"))\n",
      "2023-10-11 12:36:23,324 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,327 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:23,328 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:23,330 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,331 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:23,332 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:23,334 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:23,336 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:23,339 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:23,342 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:23,343 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,344 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:23,346 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:23,347 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,348 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:23,349 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:23,360 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:23,370 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:23,385 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:23,398 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:23,399 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,406 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:23,408 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:23,409 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 1])\",)\n",
      "2023-10-11 12:36:23,410 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:23,411 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 0\n",
      "2023-10-11 12:36:23,412 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 1\n",
      "2023-10-11 12:36:23,414 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 2\n",
      "2023-10-11 12:36:23,416 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_tokens, batch: 3\n",
      "2023-10-11 12:36:23,417 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:23,418 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_tokens\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,419 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_positions to cpu\n",
      "2023-10-11 12:36:23,421 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:23,426 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class 'torch.Tensor'>: torch.Size([8, 38])\", \"<class 'int'>: 37\")\n",
      "2023-10-11 12:36:23,426 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:23,427 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 0\n",
      "2023-10-11 12:36:23,429 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 1\n",
      "2023-10-11 12:36:23,431 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 2\n",
      "2023-10-11 12:36:23,432 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.embed_positions, batch: 3\n",
      "2023-10-11 12:36:23,434 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:23,435 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.embed_positions\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,439 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.0 to cpu\n",
      "2023-10-11 12:36:23,444 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:23,449 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,450 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,451 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 0\n",
      "2023-10-11 12:36:23,460 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 1\n",
      "2023-10-11 12:36:23,465 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 2\n",
      "2023-10-11 12:36:23,472 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.0, batch: 3\n",
      "2023-10-11 12:36:23,480 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,481 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.0\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,483 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.1 to cpu\n",
      "2023-10-11 12:36:23,488 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:23,493 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,494 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,495 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 0\n",
      "2023-10-11 12:36:23,502 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 1\n",
      "2023-10-11 12:36:23,508 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 2\n",
      "2023-10-11 12:36:23,515 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.1, batch: 3\n",
      "2023-10-11 12:36:23,521 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,522 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.1\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,525 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.2 to cpu\n",
      "2023-10-11 12:36:23,530 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:23,535 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,536 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,537 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 0\n",
      "2023-10-11 12:36:23,547 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 1\n",
      "2023-10-11 12:36:23,556 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 2\n",
      "2023-10-11 12:36:23,563 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.2, batch: 3\n",
      "2023-10-11 12:36:23,569 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,570 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.2\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,572 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.3 to cpu\n",
      "2023-10-11 12:36:23,577 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:23,582 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,582 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,583 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 0\n",
      "2023-10-11 12:36:23,592 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 1\n",
      "2023-10-11 12:36:23,598 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 2\n",
      "2023-10-11 12:36:23,603 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.3, batch: 3\n",
      "2023-10-11 12:36:23,611 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,612 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.3\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,614 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.4 to cpu\n",
      "2023-10-11 12:36:23,619 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:23,624 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,624 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,625 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 0\n",
      "2023-10-11 12:36:23,632 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 1\n",
      "2023-10-11 12:36:23,638 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 2\n",
      "2023-10-11 12:36:23,644 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.4, batch: 3\n",
      "2023-10-11 12:36:23,652 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,652 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.4\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,655 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.5 to cpu\n",
      "2023-10-11 12:36:23,660 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:23,665 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,665 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,666 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 0\n",
      "2023-10-11 12:36:23,734 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 1\n",
      "2023-10-11 12:36:23,779 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 2\n",
      "2023-10-11 12:36:23,806 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.5, batch: 3\n",
      "2023-10-11 12:36:23,816 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,817 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.5\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,820 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.6 to cpu\n",
      "2023-10-11 12:36:23,827 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:23,831 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,832 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,833 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 0\n",
      "2023-10-11 12:36:23,860 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 1\n",
      "2023-10-11 12:36:23,903 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 2\n",
      "2023-10-11 12:36:23,926 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.6, batch: 3\n",
      "2023-10-11 12:36:23,933 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,934 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.6\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,936 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.7 to cpu\n",
      "2023-10-11 12:36:23,941 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:23,946 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,947 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,948 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 0\n",
      "2023-10-11 12:36:23,955 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 1\n",
      "2023-10-11 12:36:23,962 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 2\n",
      "2023-10-11 12:36:23,968 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.7, batch: 3\n",
      "2023-10-11 12:36:23,974 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:23,975 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.7\n",
      "\n",
      "\n",
      "2023-10-11 12:36:23,977 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.8 to cpu\n",
      "2023-10-11 12:36:23,982 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:23,987 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:23,987 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:23,988 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 0\n",
      "2023-10-11 12:36:23,998 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 1\n",
      "2023-10-11 12:36:24,007 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 2\n",
      "2023-10-11 12:36:24,015 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.8, batch: 3\n",
      "2023-10-11 12:36:24,025 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:24,027 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.8\n",
      "\n",
      "\n",
      "2023-10-11 12:36:24,029 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.9 to cpu\n",
      "2023-10-11 12:36:24,034 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:24,038 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:24,039 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:24,040 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 0\n",
      "2023-10-11 12:36:24,046 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 1\n",
      "2023-10-11 12:36:24,052 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 2\n",
      "2023-10-11 12:36:24,057 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.9, batch: 3\n",
      "2023-10-11 12:36:24,063 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:24,063 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.9\n",
      "\n",
      "\n",
      "2023-10-11 12:36:24,066 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.10 to cpu\n",
      "2023-10-11 12:36:24,071 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:24,075 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:24,076 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:24,077 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 0\n",
      "2023-10-11 12:36:24,084 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 1\n",
      "2023-10-11 12:36:24,091 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 2\n",
      "2023-10-11 12:36:24,096 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.10, batch: 3\n",
      "2023-10-11 12:36:24,102 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:24,103 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.10\n",
      "\n",
      "\n",
      "2023-10-11 12:36:24,105 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.layers.11 to cpu\n",
      "2023-10-11 12:36:24,110 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:24,112 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:24,112 [3420557143.py:23 in new_forward] DEBUG - kwargs: {'attention_mask': \"<class 'torch.Tensor'>: torch.Size([8, 1, 1, 38])\", 'layer_head_mask': \"<class 'NoneType'>: None\", 'past_key_value': (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 37, 52])\"), 'output_attentions': \"<class 'bool'>: False\", 'use_cache': \"<class 'bool'>: True\"}\n",
      "2023-10-11 12:36:24,113 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 0\n",
      "2023-10-11 12:36:24,120 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 1\n",
      "2023-10-11 12:36:24,126 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 2\n",
      "2023-10-11 12:36:24,132 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.layers.11, batch: 3\n",
      "2023-10-11 12:36:24,138 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\", (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\", \"<class '__main__.BatchMixTensor'>: torch.Size([8, 12, 38, 52])\"))\n",
      "2023-10-11 12:36:24,139 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.layers.11\n",
      "\n",
      "\n",
      "2023-10-11 12:36:24,141 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.final_layer_norm to cpu\n",
      "2023-10-11 12:36:24,143 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:24,144 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:24,144 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:24,145 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 0\n",
      "2023-10-11 12:36:24,148 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 1\n",
      "2023-10-11 12:36:24,151 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 2\n",
      "2023-10-11 12:36:24,153 [3420557143.py:27 in new_forward] DEBUG - layer: model.decoder.final_layer_norm, batch: 3\n",
      "2023-10-11 12:36:24,154 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\n",
      "2023-10-11 12:36:24,155 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: model.decoder.final_layer_norm\n",
      "\n",
      "\n",
      "2023-10-11 12:36:24,157 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: lm_head to cpu\n",
      "2023-10-11 12:36:24,158 [model.py:251 in load_layer_weights] DEBUG - load_layer_weights: model.decoder.embed_tokens to cpu\n",
      "2023-10-11 12:36:24,160 [3420557143.py:22 in new_forward] DEBUG - args: (\"<class '__main__.BatchMixTensor'>: torch.Size([8, 1, 384])\",)\n",
      "2023-10-11 12:36:24,161 [3420557143.py:23 in new_forward] DEBUG - kwargs: {}\n",
      "2023-10-11 12:36:24,162 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 0\n",
      "2023-10-11 12:36:24,179 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 1\n",
      "2023-10-11 12:36:24,193 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 2\n",
      "2023-10-11 12:36:24,202 [3420557143.py:27 in new_forward] DEBUG - layer: lm_head, batch: 3\n",
      "2023-10-11 12:36:24,212 [3420557143.py:43 in new_forward] DEBUG - outputs after concat: <class '__main__.BatchMixTensor'>: torch.Size([8, 1, 25136])\n",
      "2023-10-11 12:36:24,214 [model.py:261 in offload_layer_weights] DEBUG - offload_layer_weights: lm_head\n",
      "\n",
      "\n",
      "2023-10-11 12:36:24,224 [test.py:40 in test_hf_gen] INFO - for i in range(10):  ( ( (\n",
      ",,,,,,,,,,,,,,,,, and and and and and and and and and\n",
      "2023-10-11 12:36:24,225 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,226 [test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious???,...   ...                  \n",
      "2023-10-11 12:36:24,226 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,228 [test.py:40 in test_hf_gen] INFO - Where is Deutschland?ooooooooooooooooooo's,, and and and and and and and and\n",
      "2023-10-11 12:36:24,228 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,229 [test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?oooooo   ...                  \n",
      "2023-10-11 12:36:24,230 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,231 [test.py:40 in test_hf_gen] INFO - for i in range(10):  ( to\n",
      ":::,,,,,,,,,,,,,,,, and and and and and and and and\n",
      "2023-10-11 12:36:24,232 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,233 [test.py:40 in test_hf_gen] INFO - Who are you? Are you conscious??                             \n",
      "2023-10-11 12:36:24,234 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,235 [test.py:40 in test_hf_gen] INFO - Where is Deutschland?oooooooooooooooooo's's, and and and and and and and and and\n",
      "2023-10-11 12:36:24,235 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,236 [test.py:40 in test_hf_gen] INFO - How is Huawei Mate 60 Pro?ooooo                         \n",
      "2023-10-11 12:36:24,237 [test.py:41 in test_hf_gen] INFO - ----------\n",
      "2023-10-11 12:36:24,250 [520681597.py:17 in reset_forward] DEBUG - model.decoder.embed_tokens from flexgen to old.\n",
      "2023-10-11 12:36:24,252 [520681597.py:17 in reset_forward] DEBUG - model.decoder.embed_positions from flexgen to old.\n",
      "2023-10-11 12:36:24,253 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.0 from flexgen to old.\n",
      "2023-10-11 12:36:24,254 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.1 from flexgen to old.\n",
      "2023-10-11 12:36:24,255 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.2 from flexgen to old.\n",
      "2023-10-11 12:36:24,256 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.3 from flexgen to old.\n",
      "2023-10-11 12:36:24,256 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.4 from flexgen to old.\n",
      "2023-10-11 12:36:24,257 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.5 from flexgen to old.\n",
      "2023-10-11 12:36:24,258 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.6 from flexgen to old.\n",
      "2023-10-11 12:36:24,259 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.7 from flexgen to old.\n",
      "2023-10-11 12:36:24,260 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.8 from flexgen to old.\n",
      "2023-10-11 12:36:24,261 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.9 from flexgen to old.\n",
      "2023-10-11 12:36:24,262 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.10 from flexgen to old.\n",
      "2023-10-11 12:36:24,262 [520681597.py:17 in reset_forward] DEBUG - model.decoder.layers.11 from flexgen to old.\n",
      "2023-10-11 12:36:24,264 [520681597.py:17 in reset_forward] DEBUG - model.decoder.final_layer_norm from flexgen to old.\n",
      "2023-10-11 12:36:24,264 [520681597.py:17 in reset_forward] DEBUG - lm_head from flexgen to old.\n",
      "100%|██████████| 197/197 [00:00<00:00, 3841.22it/s]\n"
     ]
    }
   ],
   "source": [
    "with flexgen(checkpoint, policy) as model:\n",
    "    num_prompts = policy.gpu_batch_size * policy.num_gpu_batches\n",
    "    test_hf_gen(checkpoint, model, num_prompts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
